# Comparing `tmp/dtps_http-1.1.1-py3-none-any.whl.zip` & `tmp/dtps_http-1.2.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,44 +1,44 @@
-Zip file size: 154949 bytes, number of entries: 42
+Zip file size: 156094 bytes, number of entries: 42
 -rw-r--r--  2.0 unx      235 b- defN 80-Jan-01 00:00 dtps/__init__.py
 -rw-r--r--  2.0 unx     6709 b- defN 80-Jan-01 00:00 dtps/config.py
--rw-r--r--  2.0 unx    12056 b- defN 80-Jan-01 00:00 dtps/ergo_create.py
+-rw-r--r--  2.0 unx    11921 b- defN 80-Jan-01 00:00 dtps/ergo_create.py
 -rw-r--r--  2.0 unx     7597 b- defN 80-Jan-01 00:00 dtps/ergo_ui.py
 -rw-r--r--  2.0 unx    12733 b- defN 80-Jan-01 00:00 dtps/ergo_use.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 dtps/py.typed
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 dtps/structures.py
 -rw-r--r--  2.0 unx      655 b- defN 80-Jan-01 00:00 dtps_http/__init__.py
--rw-r--r--  2.0 unx     5973 b- defN 80-Jan-01 00:00 dtps_http/blob_manager.py
--rw-r--r--  2.0 unx    62576 b- defN 80-Jan-01 00:00 dtps_http/client.py
--rw-r--r--  2.0 unx     3456 b- defN 80-Jan-01 00:00 dtps_http/constants.py
--rw-r--r--  2.0 unx     1349 b- defN 80-Jan-01 00:00 dtps_http/ergo_utils.py
--rw-r--r--  2.0 unx      369 b- defN 80-Jan-01 00:00 dtps_http/exceptions.py
+-rw-r--r--  2.0 unx     4861 b- defN 80-Jan-01 00:00 dtps_http/blob_manager.py
+-rw-r--r--  2.0 unx    62663 b- defN 80-Jan-01 00:00 dtps_http/client.py
+-rw-r--r--  2.0 unx     3576 b- defN 80-Jan-01 00:00 dtps_http/constants.py
+-rw-r--r--  2.0 unx     1365 b- defN 80-Jan-01 00:00 dtps_http/ergo_utils.py
+-rw-r--r--  2.0 unx      420 b- defN 80-Jan-01 00:00 dtps_http/exceptions.py
 -rw-r--r--  2.0 unx     1672 b- defN 80-Jan-01 00:00 dtps_http/link_headers.py
--rw-r--r--  2.0 unx    10313 b- defN 80-Jan-01 00:00 dtps_http/object_queue.py
+-rw-r--r--  2.0 unx    10357 b- defN 80-Jan-01 00:00 dtps_http/object_queue.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 dtps_http/py.typed
--rw-r--r--  2.0 unx    74898 b- defN 80-Jan-01 00:00 dtps_http/server.py
+-rw-r--r--  2.0 unx    75027 b- defN 80-Jan-01 00:00 dtps_http/server.py
 -rw-r--r--  2.0 unx     9695 b- defN 80-Jan-01 00:00 dtps_http/server_start.py
--rw-r--r--  2.0 unx    16233 b- defN 80-Jan-01 00:00 dtps_http/structures.py
+-rw-r--r--  2.0 unx    16304 b- defN 80-Jan-01 00:00 dtps_http/structures.py
 -rw-r--r--  2.0 unx     3555 b- defN 80-Jan-01 00:00 dtps_http/types.py
 -rw-r--r--  2.0 unx    21400 b- defN 80-Jan-01 00:00 dtps_http/types_of_source.py
 -rw-r--r--  2.0 unx     4336 b- defN 80-Jan-01 00:00 dtps_http/urls.py
--rw-r--r--  2.0 unx     6114 b- defN 80-Jan-01 00:00 dtps_http/utils.py
+-rw-r--r--  2.0 unx     6139 b- defN 80-Jan-01 00:00 dtps_http/utils.py
 -rw-r--r--  2.0 unx      838 b- defN 80-Jan-01 00:00 dtps_http/utils_every_once_in_a_while.py
 -rw-r--r--  2.0 unx      257 b- defN 80-Jan-01 00:00 dtps_http_programs/__init__.py
 -rw-r--r--  2.0 unx     3671 b- defN 80-Jan-01 00:00 dtps_http_programs/dtps_listen.py
 -rw-r--r--  2.0 unx     1721 b- defN 80-Jan-01 00:00 dtps_http_programs/dtps_proxy.py
 -rw-r--r--  2.0 unx     1338 b- defN 80-Jan-01 00:00 dtps_http_programs/dtps_send_continuous.py
 -rw-r--r--  2.0 unx     3112 b- defN 80-Jan-01 00:00 dtps_http_programs/dtps_stats.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 dtps_http_programs/py.typed
 -rw-r--r--  2.0 unx     1789 b- defN 80-Jan-01 00:00 dtps_http_programs/server_clock.py
--rw-r--r--  2.0 unx     4676 b- defN 80-Jan-01 00:00 dtps_http_programs/test_memory.py
+-rw-r--r--  2.0 unx     4682 b- defN 80-Jan-01 00:00 dtps_http_programs/test_memory.py
 -rw-r--r--  2.0 unx     3267 b- defN 80-Jan-01 00:00 dtps_http_programs/test_memory_dashboard.py
--rw-r--r--  2.0 unx     5251 b- defN 80-Jan-01 00:00 dtps_http_programs/test_memory_use.py
--rw-r--r--  2.0 unx      129 b- defN 80-Jan-01 00:00 static/favicon.png
+-rw-r--r--  2.0 unx     5257 b- defN 80-Jan-01 00:00 dtps_http_programs/test_memory_use.py
+-rw-r--r--  2.0 unx     1270 b- defN 80-Jan-01 00:00 static/favicon.png
 -rw-r--r--  2.0 unx     7885 b- defN 80-Jan-01 00:00 static/send.js
 -rw-r--r--  2.0 unx     1472 b- defN 80-Jan-01 00:00 static/style.css
--rw-r--r--  2.0 unx    75933 b- defN 80-Jan-01 00:00 dtps_http-1.1.1.dist-info/LICENSE.pdf
--rw-r--r--  2.0 unx     1001 b- defN 80-Jan-01 00:00 dtps_http-1.1.1.dist-info/METADATA
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 dtps_http-1.1.1.dist-info/WHEEL
--rw-r--r--  2.0 unx      379 b- defN 80-Jan-01 00:00 dtps_http-1.1.1.dist-info/entry_points.txt
-?rw-r--r--  2.0 unx     3394 b- defN 16-Jan-01 00:00 dtps_http-1.1.1.dist-info/RECORD
-42 files, 378125 bytes uncompressed, 149601 bytes compressed:  60.4%
+-rw-r--r--  2.0 unx    75933 b- defN 80-Jan-01 00:00 dtps_http-1.2.0.dist-info/LICENSE.pdf
+-rw-r--r--  2.0 unx     1001 b- defN 80-Jan-01 00:00 dtps_http-1.2.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 dtps_http-1.2.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx      379 b- defN 80-Jan-01 00:00 dtps_http-1.2.0.dist-info/entry_points.txt
+?rw-r--r--  2.0 unx     3395 b- defN 16-Jan-01 00:00 dtps_http-1.2.0.dist-info/RECORD
+42 files, 378575 bytes uncompressed, 150746 bytes compressed:  60.2%
```

## zipnote {}

```diff
@@ -105,23 +105,23 @@
 
 Filename: static/send.js
 Comment: 
 
 Filename: static/style.css
 Comment: 
 
-Filename: dtps_http-1.1.1.dist-info/LICENSE.pdf
+Filename: dtps_http-1.2.0.dist-info/LICENSE.pdf
 Comment: 
 
-Filename: dtps_http-1.1.1.dist-info/METADATA
+Filename: dtps_http-1.2.0.dist-info/METADATA
 Comment: 
 
-Filename: dtps_http-1.1.1.dist-info/WHEEL
+Filename: dtps_http-1.2.0.dist-info/WHEEL
 Comment: 
 
-Filename: dtps_http-1.1.1.dist-info/entry_points.txt
+Filename: dtps_http-1.2.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: dtps_http-1.1.1.dist-info/RECORD
+Filename: dtps_http-1.2.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## dtps/__init__.py

```diff
@@ -1,8 +1,8 @@
-__version__ = "1.1.1"
+__version__ = "1.2.0"
 
 from logging import DEBUG, getLogger
 
 logger = getLogger(__name__)
 logger.setLevel(DEBUG)
 
 from .config import *
```

## dtps/ergo_create.py

```diff
@@ -115,60 +115,61 @@
 class ContextManagerCreateContext(DTPSContext):
     _publisher: ContextManagerCreateContextPublisher
 
     def __init__(self, master: ContextManagerCreate, components: Tuple[str, ...]):
         self.master = master
         self.components = components
         self._publisher = ContextManagerCreateContextPublisher(self)
+        self._topic = TopicNameV.from_components(components)
 
     async def aclose(self) -> None:
         await self.master.aclose()
 
     async def get_urls(self) -> List[URLString]:
         server = self._get_server()
         urls = server.available_urls
 
-        rurl = self._get_components_as_topic().as_relative_url()
+        rurl = self._topic.as_relative_url()
         res = []
         for u in urls:
             u2 = parse_url_unescape(u)
             um = join(u2, rurl)
             res.append(url_to_string(um))
 
         for u in res:
             parse_url_unescape(u)
         return res
 
     async def get_node_id(self) -> Optional[NodeID]:
         server = self._get_server()
-        topic = self._get_components_as_topic()
+        topic = self._topic
         resolve = server._resolve_tn(topic, url0=topic.as_relative_url())
         # server.logger.info(f"get_node_id - resolve: {resolve}")
         return await resolve.get_source_node_id(server)
 
     def _get_server(self) -> DTPSServer:
         if self.master.dtps_server_wrap is None:
             raise AssertionError("ContextManagerCreateContext: server not initialized")
         return self.master.dtps_server_wrap.server
 
-    def _get_components_as_topic(self) -> TopicNameV:
-        return TopicNameV.from_components(self.components)
+    # def _get_components_as_topic(self) -> TopicNameV:
+    #     return TopicNameV.from_components(self.components)
 
     def navigate(self, *components: str) -> "DTPSContext":
         c = []
         for comp in components:
             c.extend([_ for _ in comp.split("/") if _])
         return self.master.get_context_by_components(self.components + tuple(c))
 
     async def list(self) -> List[str]:
         # TODO: DTSW-4798: implement list
         raise NotImplementedError()
 
     async def remove(self) -> None:
-        topic = self._get_components_as_topic()
+        topic = self._topic
         server = self._get_server()
         try:
             source = server._resolve_tn(topic, url0=topic.as_relative_url())
         except KeyError:
             raise
 
         if isinstance(source, OurQueue):
@@ -180,25 +181,25 @@
             msg = "Cannot remove a source composition queue"
             raise NotImplementedError(msg)
         else:
             msg = f"Cannot remove a {source}"
             raise NotImplementedError(msg)
 
     async def exists(self) -> bool:
-        topic = self._get_components_as_topic()
+        topic = self._topic
         server = self._get_server()
         try:
             server._resolve_tn(topic, url0=topic.as_relative_url())
         except KeyError:
             return False
         else:
             return True
 
     async def data_get(self) -> RawData:
-        topic = self._get_components_as_topic()
+        topic = self._topic
         server = self._get_server()
         url0 = topic.as_relative_url()
         source = server._resolve_tn(topic, url0=url0)
         res = await source.get_resolved_data(url0, server)
         if isinstance(res, RawData):
             return res
         elif isinstance(res, NotFound):
@@ -213,15 +214,15 @@
     async def subscribe(
         self,
         on_data: Callable[[RawData], Awaitable[None]],
         /,
         max_frequency: Optional[float] = None,
         inline: bool = True,
     ) -> "SubscriptionInterface":
-        oq0 = self._get_server().get_oq(self._get_components_as_topic())
+        oq0 = self._get_server().get_oq(self._topic)
 
         when = EveryOnceInAWhile(1.0 / max_frequency if max_frequency is not None else 0)
 
         async def wrap(_: ObjectQueue, inot: InsertNotification) -> None:
             if when.now():
                 await on_data(inot.raw_data)
 
@@ -236,15 +237,15 @@
 
     async def history(self) -> "Optional[HistoryInterface]":
         # TODO: DTSW-4794: implement history
         raise NotImplementedError()
 
     async def publish(self, data: RawData, /) -> None:
         server = self._get_server()
-        topic = self._get_components_as_topic()
+        topic = self._topic
         queue = server.get_oq(topic)
         await queue.publish(data)
 
     async def publisher(self) -> "PublisherInterface":
         return self._publisher
 
     @asynccontextmanager
@@ -252,15 +253,15 @@
         yield self._publisher
 
     async def patch(self, patch_data: List[Dict[str, Any]], /) -> None:
         raise NotImplementedError
 
     async def call(self, data: RawData, /) -> RawData:
         server = self._get_server()
-        topic = self._get_components_as_topic()
+        topic = self._topic
         url0 = topic.as_relative_url()
         resolve = server._resolve_tn(topic, url0=url0)
         res = await resolve.call(url0, server, data)
         # queue = server.get_oq(topic)
         # res = await queue.publish(data)
         if isinstance(res, TransformError):
             raise Exception(f"{res.http_code}: {res.message}")
@@ -273,29 +274,29 @@
             urls = await p.get_urls()
             node_id = await p.get_node_id()
         else:
             urls = cast(Sequence[URLString], p)
             node_id = None
 
         server = self._get_server()
-        topic = self._get_components_as_topic()
+        topic = self._topic
         await server.expose(topic, node_id, urls, mask_origin=mask_origin)
         return self
 
     async def queue_create(
         self,
         *,
         parameters: Optional[TopicRefAdd] = None,
         transform: Optional[RPCFunction] = None,
         bounds: Optional[Bounds] = None,
     ) -> "DTPSContext":
         if bounds is None:
             bounds = Bounds.default()
         server = self._get_server()
-        topic = self._get_components_as_topic()
+        topic = self._topic
         if parameters is None:
             parameters = TopicRefAdd(
                 content_info=ContentInfo.simple(MIME_OCTET),
                 properties=TopicProperties.rw_pushable(),
                 app_data={},
                 bounds=bounds,
             )
```

## dtps_http/__init__.py

```diff
@@ -1,8 +1,8 @@
-__version__ = "1.1.1"
+__version__ = "1.2.0"
 
 import coloredlogs  # type: ignore
 
 coloredlogs.install(level="DEBUG")  # type: ignore
 
 from logging import getLogger, INFO, WARNING
```

## dtps_http/blob_manager.py

```diff
@@ -1,18 +1,18 @@
 import base64
 import time
 import uuid
 from dataclasses import dataclass
 from typing import Dict, Set, Tuple
 
-from .types import URLString
 from .structures import (
     Digest,
     get_digest,
 )
+from .types import URLString
 
 __all__ = [
     "BlobManager",
 ]
 
 from .utils_every_once_in_a_while import EveryOnceInAWhile
 
@@ -138,41 +138,14 @@
             self.blobs[digest] = SavedBlob(
                 content=content,
                 who_needs_it=set(),
                 outstanding_tokens={},
             )
         return self.blobs[digest]
 
-    # def save_blob_deadline(self, content: bytes, deadline: float) -> Digest:
-    #     now = time.time()
-    #     if deadline < now - 3:
-    #         raise ValueError(f"The deadline {deadline} is supposed to be a time in the future")
-    #     self.cleanup_blobs_if_its_time()
-    #     digest = get_digest(content)
-    #     if digest not in self.blobs:
-    #         self.blobs[digest] = SavedBlob.make(content)
-    #     else:
-    #         sb = self.blobs[digest]
-    #         sb.deadline = max(deadline, sb.deadline)
-    #     return digest
-
-    # def get_blob_deadline(self, digest: Digest) -> float:
-    #     if digest not in self.blobs:
-    #         raise ValueError(f"Blob {digest} not found")
-    #     sb = self.blobs[digest]
-    #     return sb.deadline
-
-    # def extend_deadline(self, digest: Digest, seconds: float) -> float:
-    #     if digest not in self.blobs:
-    #         raise ValueError(f"Blob {digest} not found")
-    #     sb = self.blobs[digest]
-    #     new_deadline = time.time() + seconds
-    #     sb.deadline = max(sb.deadline, new_deadline)
-    #     return sb.deadline
-
 
 def encode_url2(digest: Digest, content_type: str, token: str) -> URLString:
     if not content_type:
         raise ValueError(f"Cannot encode url for empty content type")
     b64 = base64.urlsafe_b64encode(content_type.encode()).decode("ascii")
 
     url = URLString(f"./:blobs/{digest}/{b64}/{token}")
```

## dtps_http/client.py

```diff
@@ -33,14 +33,15 @@
     ClientWebSocketResponse,
     TCPConnector,
     UnixConnector,
     WSCloseCode,
 )
 from multidict import CIMultiDictProxy
 from tcp_latency import measure_latency
+from urllib3.exceptions import LocationParseError
 
 from . import logger, logger as logger0
 from .constants import (
     CONTENT_TYPE_PATCH_CBOR,
     CONTENT_TYPE_PATCH_JSON,
     HEADER_CONTENT_LOCATION,
     HEADER_DATA_ORIGIN_NODE_ID,
@@ -101,14 +102,16 @@
     method_lru_cache,
     parse_cbor_tagged,
     pretty,
 )
 
 __all__ = [
     "DTPSClient",
+    "FoundMetadata",
+    "ListenDataInterface",
     "StopContinuousLoop",
     "escape_json_pointer",
     "my_raise_for_status",
     "unescape_json_pointer",
 ]
 
 U = TypeVar("U", bound=URL)
@@ -292,15 +295,15 @@
                 res = cbor2.loads(res_bytes)
 
             alternatives0 = cast(List[URLString], resp.headers.getall(HEADER_CONTENT_LOCATION, []))
             where_this_available: List[URL] = [url]
             for a in alternatives0:
                 try:
                     x = parse_url_unescape(a)
-                except Exception:
+                except ValueError:
                     self.logger.exception(f"cannot parse {a}")
                     continue
                 else:
                     where_this_available.append(x)
 
             s = TopicsIndexWire.from_json(res)
             q = s.to_internal([url])
@@ -347,15 +350,15 @@
 
         if not alternatives0:
             return None
         alternatives: list[URL] = [current]
         for a in alternatives0:
             try:
                 x = parse_url_unescape(a)
-            except Exception:
+            except ValueError:
                 self.logger.exception(f"cannot parse {a}")
                 continue
             else:
                 alternatives.append(x)
         answering = cast(NodeID, resp.headers.get(HEADER_NODE_ID))
 
         #  noinspection PyTypeChecker
@@ -649,36 +652,36 @@
                     }
                 )
         # add
         proxy_job = ProxyJob(node_id, urls, mask_origin)
         patch.append({"op": "add", "path": path, "value": asdict(proxy_job)})
         # compile patch
         as_json = json.dumps(patch).encode("utf-8")
-        # FIXME: need to use REL_PROXIED
+        # FIXME: DTSW-5454: need to use REL_PROXIED
         url = join(url0, TOPIC_PROXIED.as_relative_url())
-        res = await self.patch(url, CONTENT_TYPE_PATCH_JSON, as_json)
+        await self.patch(url, CONTENT_TYPE_PATCH_JSON, as_json)
         return True
 
     async def remove_proxy(self, url0: URLIndexer, topic_name: TopicNameV) -> None:
         patch = [{"op": "remove", "path": "/" + escape_json_pointer(topic_name.as_dash_sep())}]
         as_json = json.dumps(patch).encode("utf-8")
-        # FIXME: need to use REL_PROXIED
+        # FIXME: DTSW-5454: need to use REL_PROXIED
         url = join(url0, TOPIC_PROXIED.as_relative_url())
-        res = await self.patch(url, CONTENT_TYPE_PATCH_JSON, as_json)
+        await self.patch(url, CONTENT_TYPE_PATCH_JSON, as_json)
 
     async def add_topic(self, url0: URLIndexer, topic_name: TopicNameV, tra: TopicRefAdd) -> None:
         path = "/" + escape_json_pointer(topic_name.as_dash_sep())
         patch = jsonpatch.JsonPatch(
             [
                 {"op": "add", "path": path, "value": asdict(tra)},
             ]
         )
         patch_json = patch.to_string().encode()
 
-        res = await self.patch(url0, CONTENT_TYPE_PATCH_JSON, patch_json)
+        await self.patch(url0, CONTENT_TYPE_PATCH_JSON, patch_json)
 
     async def patch(self, url0: URL, content_type: Optional[str], data: bytes) -> RawData:
         headers = {"content-type": content_type} if content_type is not None else {}
 
         url = self._look_cache(url0)
         use_url = None
         try:
@@ -687,15 +690,15 @@
                     res_bytes: bytes = await resp.read()
                     content_type = ContentType(resp.headers.get("content-type", MIME_OCTET))
                     rd = RawData(content=res_bytes, content_type=content_type)
 
                     if not resp.ok:
                         try:
                             message = res_bytes.decode("utf-8")
-                        except:
+                        except UnicodeDecodeError:
                             message = res_bytes
                         raise ValueError(f"cannot patch {url0=!r} {use_url=!r} {resp=!r}\n{message}")
 
                     return rd
 
         except CancelledError:
             raise
@@ -716,15 +719,15 @@
                     res_bytes: bytes = await resp.read()
                     content_type = ContentType(resp.headers.get("content-type", "application/octet-stream"))
                     rd = RawData(content=res_bytes, content_type=content_type)
 
                     if not resp.ok:
                         try:
                             message = res_bytes.decode("utf-8")
-                        except:
+                        except UnicodeDecodeError:
                             message = res_bytes
                         resp: ClientResponse = resp
                         if resp.status == 404:
                             raise NoSuchTopic(f"cannot GET {url0=!r}\n{use_url=!r}\n{resp=!r}\n{message}")
                         if resp.status == 503:
                             raise TopicOriginUnavailable(
                                 f"cannot GET {url0=!r}\n{use_url=!r}\n{resp=!r}\n{message}"
@@ -743,21 +746,21 @@
         except TopicOriginUnavailable:
             raise
         except:
             self.logger.error(f"cannot connect to {url=!r} {use_url=!r} \n{traceback.format_exc()}")
             raise
 
     async def delete(self, url0: URL) -> None:
-        headers: dict[str, str] = {}
+        # headers: dict[str, str] = {}
 
         url = self._look_cache(url0)
-        use_url = None
+        # use_url = None
         async with self.my_session(url, conn_timeout=HTTP_TIMEOUT) as (session, use_url):
             async with session.delete(use_url) as resp:
-                res_bytes: bytes = await resp.read()
+                # res_bytes: bytes = await resp.read()
                 resp.raise_for_status()
 
     async def get_metadata(self, url0: URLTopic) -> FoundMetadata:
         url = self._look_cache(url0)
         use_url = None
         try:
             async with self.my_session(url, conn_timeout=HTTP_TIMEOUT) as (session, use_url):
@@ -839,15 +842,15 @@
         )
 
     async def choose_best(self, reachability: List[TopicReachability]) -> URL:
         use: List[Tuple[URL, Optional[NodeID]]] = []
         for r in reachability:
             try:
                 x = parse_url_unescape(r.url)
-            except Exception:
+            except ValueError:
                 self.logger.exception(f"cannot parse {r.url}")
                 continue
             else:
                 use.append((x, r.answering))
         res = await self.find_best_alternative(use)
         if res is None:
             msg = f"no reachable url for {reachability}"
@@ -964,19 +967,20 @@
             elif isinstance(lue, FinishedMsg):
                 logger.debug(f"finished in {url_events}: {lue.comment}")
             elif isinstance(lue, ConnectionEstablished):
                 logger.debug(f"connection established in {url_events}")
 
                 connection_event.set()
             elif isinstance(lue, InsertNotification):
+                # noinspection PyBroadException
                 try:
                     await cb(lue.raw_data)
                 except CancelledError:
                     raise
-                except:
+                except Exception:  #
                     logger.error(f"error in handler: {traceback.format_exc()}")
                     return
             else:
                 logger.error(f"unknown {lue}")
                 raise ValueError(f"unknown {lue}")
 
         li = await self.listen_url_events3(
@@ -1446,41 +1450,37 @@
                     raise_on_error=raise_on_error,
                     inline_data=True,
                     add_silence=add_silence,
                     max_frequency=max_frequency,
                     callback=callback,
                 )
 
-            should_break_outer = False
             try:
                 try:
                     finish = asyncio.create_task(listen_data.wait_for_done())
                     try:
                         await self._wait_until_shutdown(finish, ldi.stop_condition)
                     except ShutdownAsked:
                         return
                     except ConditionSatistied:
                         return
 
                 except StopContinuousLoop as e:
                     self.logger.error(f"obtained {e}")
-                    should_break_outer = True
                     break
             except CancelledError:
                 raise
             except Exception as e:
                 msg = f"Error listening to {urlbase0!r}:\n{traceback.format_exc()}"
                 self.logger.error(msg)
                 if raise_on_error:
                     raise Exception(msg) from e
                 await asyncio.sleep(1.0)
                 continue
 
-            if should_break_outer:
-                break
             await asyncio.sleep(1.0)
 
     @async_error_catcher
     async def push_continuous(
         self,
         urlbase0: URL,
         *,
@@ -1550,15 +1550,15 @@
 async def my_raise_for_status(resp: ClientResponse, url0: URL) -> None:
     if not resp.ok:
         # reason should always be not None for a started response
         assert resp.reason is not None
         msg = await resp.read()
         try:
             msg = msg.decode("utf-8")
-        except:
+        except UnicodeDecodeError:
             pass
 
         message = ""
         message += f"method: {resp.method}\n"
         message += f"url0: {url_to_string(url0)}\n"
         message += f"reason: {resp.reason}\n"
         message += f"msg:\n{msg}\n"
```

## dtps_http/constants.py

```diff
@@ -13,31 +13,36 @@
     "DEFAULT_MAX_HISTORY",
     "ENV_MASK_ORIGIN",
     "EVENTS_SUFFIX",
     "HEADER_CONTENT_LOCATION",
     "HEADER_DATA_ORIGIN_NODE_ID",
     "HEADER_DATA_UNIQUE_ID",
     "HEADER_LINK_BENCHMARK",
+    "HEADER_MAX_FREQUENCY",
     "HEADER_NODE_ID",
     "HEADER_NODE_PASSED_THROUGH",
     "HEADER_NO_AVAIL",
     "HEADER_NO_CACHE",
+    "HTTP_TIMEOUT",
     "MIME_CBOR",
     "MIME_HTML",
     "MIME_JPEG",
     "MIME_JSON",
     "MIME_OCTET",
     "MIME_TEXT",
     "MIME_YAML",
     "REL_CONNECTIONS",
     "REL_EVENTS_DATA",
     "REL_EVENTS_NODATA",
     "REL_HISTORY",
     "REL_HISTORY",
     "REL_META",
+    "REL_PROXIED",
+    "REL_STREAM_PUSH",
+    "REL_STREAM_PUSH_SUFFIX",
     "REL_URL_HISTORY",
     "REL_URL_META",
     "TOPIC_AVAILABILITY",
     "TOPIC_CLOCK",
     "TOPIC_CONNECTIONS",
     "TOPIC_LIST",
     "TOPIC_LOGS",
```

## dtps_http/ergo_utils.py

```diff
@@ -32,10 +32,10 @@
 
 def reapply_decorators(cls):
     for b in cls.__bases__:
         for attr_name, attr_value in cls.__dict__.items():
             if callable(attr_value):
                 base_method = getattr(b, attr_name, None)
                 if base_method and hasattr(base_method, "_allowed_exceptions"):
-                    allowed_exceptions = base_method._allowed_exceptions
+                    allowed_exceptions = base_method._allowed_exceptions  # type: ignore
                     setattr(cls, attr_name, allow_exceptions(*allowed_exceptions)(attr_value))
     return cls
```

## dtps_http/exceptions.py

```diff
@@ -1,11 +1,13 @@
 __all__ = [
     "DTPSClientException",
+    "DTPSException",
     "EventListeningNotAvailable",
     "NoSuchTopic",
+    "TopicOriginUnavailable",
 ]
 
 
 class DTPSException(Exception):
     pass
```

## dtps_http/object_queue.py

```diff
@@ -31,15 +31,17 @@
 from .types import ContentType, TopicNameV
 
 __all__ = [
     "ObjectQueue",
     "ObjectTransformContext",
     "ObjectTransformFunction",
     "ObjectTransformResult",
+    "PostResult",
     "TransformError",
+    "transform_identity",
 ]
 
 SUB_ID = int
 K_INDEX = "index"
 
 
 @original_dataclass
```

## dtps_http/server.py

```diff
@@ -25,14 +25,15 @@
 )
 
 import cbor2
 import yaml
 from aiohttp import web, WSMsgType
 from aiohttp.web_exceptions import HTTPBadRequest
 from aiopubsub import Hub
+from cbor2 import CBORDecodeError
 from jsonpatch import (
     AddOperation,
     CopyOperation,
     JsonPatch,
     MoveOperation,
     RemoveOperation,
     ReplaceOperation,
@@ -131,14 +132,15 @@
 
 SEND_DATA_ARGNAME = "send_data"
 ROOT = TopicNameV.root()
 
 __all__ = [
     "DTPSServer",
     "ForwardedTopic",
+    "get_tagged_cbor",
 ]
 
 
 @dataclass
 class ForwardedTopic:
     unique_id: SourceID  # unique id for the stream
     origin_node: NodeID  # unique id of the node that created the stream
@@ -1632,17 +1634,17 @@
                         pass
 
         s = oq_.subscribe(send_message)
 
         if oq_.stored:
             last = oq_.last()
             last_data = oq_.last_data()
-            inot = InsertNotification(last, last_data)
+            inot2 = InsertNotification(last, last_data)
 
-            await send_message(oq_, inot)
+            await send_message(oq_, inot2)
 
         try:
             await exit_event.wait()
             await ws.close()
         finally:
             await oq_.unsubscribe(s)
 
@@ -1680,15 +1682,15 @@
             if wm.type == WSMsgType.CLOSE:
                 break
 
             elif wm.type == WSMsgType.BINARY:
                 # read cbor
                 try:
                     data = cbor2.loads(wm.data)
-                except:
+                except CBORDecodeError:
                     msg = f"Cannot decode {wm.data!r}"
                     self.logger.error(msg)
                     result = PushResult(False, msg)
                     await ws.send_bytes(get_tagged_cbor(result))
                     continue
                 # logger.info(f"received: {data}")
                 # interpret as RawData
@@ -1734,14 +1736,15 @@
         inline_data: bool,
         max_frequency: Optional[float],
     ) -> None:
         # assert fd.forward_url_events is not None
         while not self.shutdown_event.is_set():
             if ws.closed:
                 break
+            # noinspection PyBroadException
             try:
                 if inline_data:
                     if (url := fd.forward_url_events_inline_data) is not None:
                         await self.serve_events_forward_simple(ws, url)
                     elif (url := fd.forward_url_events) is not None:
                         await self.serve_events_forwarder_one(
                             ws,
@@ -1770,15 +1773,15 @@
                         inline_data_send=inline_data,
                         inline_data_receive=inline_data_receive,
                         max_frequency=max_frequency,
                     )
 
             except CancelledError:
                 raise
-            except:
+            except Exception:
                 self.logger.error(f"Exception in serve_events_forwarder_one: {traceback.format_exc()}")
                 await asyncio.sleep(1)
 
     if TYPE_CHECKING:
 
         def _client(self, nickname: Optional[str] = None) -> AsyncContextManager[DTPSClient]: ...
```

## dtps_http/structures.py

```diff
@@ -16,40 +16,44 @@
     "Bounds",
     "ChannelInfo",
     "ChannelInfoDesc",
     "ChannelMsgs",
     "Chunk",
     "Clocks",
     "ConnectionEstablished",
+    "ConnectionJob",
     "ContentInfo",
     "DataDesc",
     "DataReady",
     "DataSaved",
+    "Digest",
     "ErrorMsg",
     "FinishedMsg",
     "ForwardingStep",
     "History",
     "InsertNotification",
     "LinkBenchmark",
     "ListenURLEvents",
     "Metadata",
     "MinMax",
     "ProxyJob",
+    "PushResult",
     "RawData",
     "Registration",
     "ResourceAvailability",
     "SilenceMsg",
     "TopicProperties",
     "TopicReachability",
     "TopicRef",
     "TopicRefAdd",
     "TopicsIndex",
     "TopicsIndexWire",
     "TransportData",
     "WarningMsg",
+    "get_digest",
     "is_image",
     "is_structure",
 ]
 
 
 @dataclass
 class LinkBenchmark:
```

## dtps_http/utils.py

```diff
@@ -35,14 +35,15 @@
 
 __all__ = [
     "async_error_catcher",
     "async_error_catcher_iterator",
     "check_is_unix_socket",
     "method_lru_cache",
     "multidict_update",
+    "parse_cbor_tagged",
     "parse_tagged",
     "pretty",
     "pydantic_parse",
     "should_mask_origin",
     "wait_for_unix_socket",
 ]
```

## dtps_http_programs/__init__.py

```diff
@@ -1,8 +1,8 @@
-__version__ = "1.1.1"
+__version__ = "1.2.0"
 
 from logging import DEBUG, getLogger
 
 logger = getLogger(__name__)
 logger.setLevel(DEBUG)
 
 from .server_clock import *
```

## dtps_http_programs/test_memory.py

```diff
@@ -67,15 +67,15 @@
             for o in obs:
                 if o is obs:
                     continue
                 if isinstance(o, (type, bytes)):
                     continue
                 try:
                     l = len(o)
-                except:
+                except:  # OK
                     pass
                 else:
                     if l > 500:
                         print(f"found {type(o)} of length {l}")
                         if l > 50000:
                             print("first element", o[0])
                             print("last element", o[-1])
```

## dtps_http_programs/test_memory_use.py

```diff
@@ -71,15 +71,15 @@
                 for o in obs:
                     if o is obs:
                         continue
                     if isinstance(o, (type, bytes)):
                         continue
                     try:
                         l = len(o)
-                    except:
+                    except:  # OK
                         pass
                     else:
                         if l > 500:
                             print(f"found {type(o)} of length {l}")
                             if l > 50000:
                                 print("first element", o[0])
                                 print("last element", o[-1])
```

## static/favicon.png

```diff
@@ -1,9 +1,80 @@
-00000000: 7665 7273 696f 6e20 6874 7470 733a 2f2f  version https://
-00000010: 6769 742d 6c66 732e 6769 7468 7562 2e63  git-lfs.github.c
-00000020: 6f6d 2f73 7065 632f 7631 0a6f 6964 2073  om/spec/v1.oid s
-00000030: 6861 3235 363a 3461 6561 3033 3739 6331  ha256:4aea0379c1
-00000040: 3035 6363 3931 6237 3435 6136 6437 6234  05cc91b745a6d7b4
-00000050: 6561 3166 3438 3137 3038 3365 3330 6531  ea1f4817083e30e1
-00000060: 3239 3532 6533 3134 3164 3134 3566 6632  2952e3141d145ff2
-00000070: 6436 6532 6432 0a73 697a 6520 3132 3730  d6e2d2.size 1270
-00000080: 0a                                       .
+00000000: 8950 4e47 0d0a 1a0a 0000 000d 4948 4452  .PNG........IHDR
+00000010: 0000 0064 0000 0064 0806 0000 0070 e295  ...d...d.....p..
+00000020: 5400 0000 0970 4859 7300 000b 1300 000b  T....pHYs.......
+00000030: 1301 009a 9c18 0000 04a8 4944 4154 789c  ..........IDATx.
+00000040: ed9d 4b88 1d45 1486 bf19 3251 4988 1a5d  ..K..E....2QI..]
+00000050: 8818 7561 1682 4622 3e06 147c 05f1 0106  ..ua..F">..|....
+00000060: 250b 2104 4489 5b97 e24a 4588 ae7c 4144  %.!.D.[..JE..|AD
+00000070: 372a 66d0 8d88 41c4 8d2b 21e2 6b13 5123  7*f...A..+!.k.Q#
+00000080: 3762 888a 8608 8219 938c 26cc 9592 7361  7b........&...sa
+00000090: 2caa fa91 db7d 6f75 f5ff c1d9 ccbd 7daa  ,....}ou......}.
+000000a0: eef9 bbaa 4e17 5d73 4008 2184 1042 0821  ....N.]s@.!..B.!
+000000b0: bac1 1cb0 0d58 000e 007f 01c3 9edb a2c5  .....X..........
+000000c0: 62c1 62e3 6234 11b6 0283 0402 304c dc06  b.b.b4......0L..
+000000d0: 16ab d698 059e 4de0 870e 3b64 cbc0 2e8b  ......M...;d....
+000000e0: 5de3 480c ce58 1827 4aa3 6c35 b557 3672  ].H..X.'J.l5.W6r
+000000f0: 1278 01b8 0158 d374 831d 648d c5e2 458b  .x...X.t..d...E.
+00000100: 8d3f 52ee 6baa a1b9 c09a 7118 b8aa a906  .?R.k.....q.....
+00000110: 32e4 6ae0 a7c0 9ad2 c842 bf2d 3032 2446  2.j......B.-02$F
+00000120: 3551 96bc d8b9 588e cd82 e7d4 4d53 a21a  5Q....X.....MS..
+00000130: 2f79 b1db 4303 7cef 39bd be09 a73d e146  /y..C.|.9....=.F
+00000140: 2f76 2e96 63b3 e839 5ddb 84d3 9eb0 d68b  /v..c..9].......
+00000150: 9d8b e5d8 f829 9c98 72fc 24c8 7848 90c4  .....)..r.$.xH..
+00000160: 9020 8921 4112 4382 2486 0449 0c09 9218  . .!A.C.$..I....
+00000170: 1224 3124 4862 4890 c490 2089 3175 4186  .$1$HbH... .1uA.
+00000180: 3db3 3224 0812 a4f0 8ec8 ddca d008 4182  =.2$..........A.
+00000190: b47b 4724 46e7 47c8 6bc0 6aba cf2a e0b9  .{G$F.G.k.j..*..
+000001a0: 1c04 71f6 2570 29dd e562 605f 6e6b c851  ..q.%p)..b`_nk.Q
+000001b0: e00e bac7 cdc0 afb9 2eea a780 c7e9 0e8f  ................
+000001c0: 02ff f421 cb7a 27f1 d74f cf01 dec8 35ed  ...!.z'..O....5.
+000001d0: 7d3a f05e b0b3 af81 8da4 c746 eb9b dfdf  }:.^.......F....
+000001e0: 65fb 2d9d 17c4 710f f047 e0b3 63c0 03a4  e.-...q..G..c...
+000001f0: c3bd 917e fe09 dc6f dfc9 4210 c715 c0fe  ...~...o..B.....
+00000200: c89d f74c 5b67 282a 326b 7d08 8de4 fdd6  ...L[g(*2k}.....
+00000210: 7772 13c4 7136 f07a 642e fe08 58cf e459  wr..q6.zd...X..Y
+00000220: 07bc 1fe9 d3db 81b5 2e2b 4156 662f 7f07  .........+AVf/..
+00000230: be7b 18b8 8ec9 b109 f8a1 6636 98a5 208e  .{........f6.. .
+00000240: 9b22 f9fd 49e0 21da e7c1 c861 55f7 bc74  ."..I.!....aU..t
+00000250: 7bc1 75d9 0a52 f604 fcbc 6d57 34cd 2af3  {.u..R....mW4.*.
+00000260: 1d6a 739f f589 be0a 52b4 4734 043e 012e  .js.....R.G4.>..
+00000270: a239 2e04 3e8e b455 75cf 2d7b 4146 6c07  .9..>..Uu.-{AFl.
+00000280: 8e07 aeff 0598 677c ae05 0e05 fcbb 534e  ......g|......SN
+00000290: 8fd4 f0d3 1b41 1c9b 811f 2341 dbc9 99b3  .....A....#A....
+000002a0: 0338 11f0 fbb3 1dd4 ac43 af04 d900 7c11  .8.......C....|.
+000002b0: 9952 46d3 ca59 35fc b929 e8d5 027f 9f5b  .RF..Y5..).....[
+000002c0: 9b75 e88d 20b7 0047 0a82 37b2 af80 cb2a  .u.. ..G..7....*
+000002d0: f873 8bf3 a715 fcfd 0edc 59a3 9fd9 0b32  .s........Y....2
+000002e0: 033c 019c 0e5c 7b28 929a 1e29 494d 6f03  .<...\{(...)IMo.
+000002f0: 7e0b 5cb7 1859 474e 5b1f 6612 88c7 543b  ~.\..YGN[.f...T;
+00000300: 701e b037 72e7 eeb5 cfdd f1e2 8381 cf97  p..7r...........
+00000310: 6d47 d68d ac0b cc6e 05de 8c6c 810c ec38  mG.....n...l...8
+00000320: 7751 9bee 89fd dc29 c6a3 126d 75e0 4ae0  wQ.....)...mu.J.
+00000330: bbc8 ddfa 94b7 b7e5 b637 deab 30fd c4ec  .........7..0...
+00000340: 43e0 fc15 fedc 4878 cc9e c8fd ef1e b427  C.....Hx.......'
+00000350: f849 c7a3 326d 7460 4724 c53d 0a6c 895c  .I..2mt`G$.=.l.\
+00000360: e304 7a32 32b5 c5ec 945d 13db b8dc 626d  ..z22....]....bm
+00000370: fad7 1db7 3e4e 2a1e b568 b203 2eeb d91d  ....>N*..h......
+00000380: 09de 6715 331e f74c f26d 0531 beb1 73e2  ..g.3..L.m.1..s.
+00000390: 656c b0b6 433e 7607 1e16 b311 a4e8 87bf  el..C>v.........
+000003a0: 5233 9d9d 05ee 06de b2b5 e184 d9c0 fe76  R3.............v
+000003b0: 57cd edfc d5d6 872a 374a 1682 c452 5ab7  W......*7J...RZ.
+000003c0: 91f8 30e9 b03d 92d5 ad4c 8d3b 2f48 2ca5  ..0..=...L.;/H,.
+000003d0: 2d5b 3ca7 c5a6 4856 374a 8d3b 2f48 c83e  -[<...HV7J.;/H.>
+000003e0: f0b2 9ed4 5807 bc5b f1b7 745a 9050 4a9b  ....X..[..tZ.PJ.
+000003f0: 2a33 05a9 7116 82d4 dda2 4885 b22d 9d4e  *3..q.....H..-.N
+00000400: 0ae2 f69f 2ea7 bb5c 52b0 2fd6 3941 f4b2  .......\R./.9A..
+00000410: 3569 0992 1bc3 1cb3 ac9c ac0c 0982 0429  5i.............)
+00000420: bc23 72b7 3234 4290 2022 e511 22fe 8f04  .#r.24B. ".."...
+00000430: 490c 0992 1812 2431 2448 6248 90c4 9020  I.....$1$HbH... 
+00000440: 8921 4112 4382 2486 0449 0c09 92bb 20c7  .!A.C.$..I.... .
+00000450: 3c87 2ae8 52ef ed15 ff1f 1034 5ef2 a8ee  <.*.R......4^...
+00000460: 89a3 3e33 df46 c923 bf28 98ab d327 aaf1  ..>3.F.#.(...'..
+00000470: 721b 45c1 4265 f3dc 990d 51cc 356d 95cd  r.E.Be....Q.5m..
+00000480: 8b15 9694 28c5 afa3 b656 5832 567a 75c9  ....(....VX2Vzu.
+00000490: eaf4 b979 520b 3dff c560 dea6 a9a5 364b  ...yR.=..`....6K
+000004a0: af8e 5071 62d2 294e 8cbd 8fbb 2b72 7e4f  ..Pqb.)N....+r~O
+000004b0: c6e4 cb77 8f70 434f 05ee 29bd 0907 6d4c  ...w.pCO..)...mL
+000004c0: 5331 e62c 6370 29f1 8140 35d0 3eda a21d  S1.,cp)..@5.>...
+000004d0: 62dd 63b1 696c 0117 4208 2184 1042 085a  b.c.il..B.!..B.Z
+000004e0: e45f 7106 3012 5997 31d8 0000 0000 4945  ._q.0.Y.1.....IE
+000004f0: 4e44 ae42 6082                           ND.B`.
```

## Comparing `dtps_http-1.1.1.dist-info/LICENSE.pdf` & `dtps_http-1.2.0.dist-info/LICENSE.pdf`

 * *Files identical despite different names*

## Comparing `dtps_http-1.1.1.dist-info/METADATA` & `dtps_http-1.2.0.dist-info/METADATA`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dtps-http
-Version: 1.1.1
+Version: 1.2.0
 Summary: 
 Author: Andrea Censi
 Author-email: AndreaCensi@users.noreply.github.com
 Requires-Python: >=3.8,<4.0
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
```

## Comparing `dtps_http-1.1.1.dist-info/RECORD` & `dtps_http-1.2.0.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,42 +1,42 @@
-dtps/__init__.py,sha256=U2FUja5RcrO0xRhlL9_-Pw965iPW7JxSDUIY5r091dU,235
+dtps/__init__.py,sha256=3tITP5FLeHIzanc1gepFqzJhPZ_a8J9zvxLrvud4glk,235
 dtps/config.py,sha256=pX8NyQFRER6sxKxiCCNW7rTjUR2lQyg7yi-wcTzwlDA,6709
-dtps/ergo_create.py,sha256=Y_1ucGbaOn_HWTGwNnu_Pcrw1XyHbS4n9tW61Qim-lg,12056
+dtps/ergo_create.py,sha256=awaOjfX8eVBzK_y2us3WcOTxiS3v3j7XqTVf55UKPk4,11921
 dtps/ergo_ui.py,sha256=lnP4ChQcc2hQkOxDDQEj_FG_SQc2aCEiICEPtRL2dSI,7597
 dtps/ergo_use.py,sha256=GmiZkjqiT4QhA0WprJe4N1tfKaRGD1ND3rgUOmvY4sc,12733
 dtps/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 dtps/structures.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dtps_http/__init__.py,sha256=jV_KP43j-wBTANS1GJvj7l2X39gLpEQf-DZD6jNff_w,655
-dtps_http/blob_manager.py,sha256=CO7pp9cILLJyAesdDJsd-3MPkMIs4WTgcbWgNhWGoYs,5973
-dtps_http/client.py,sha256=H6WsskD_DVBNS4n_QUGvgl_MfPtGgvchpnUXi4NaYL8,62576
-dtps_http/constants.py,sha256=KzKfzcr55qMmKx3EivFERUg_WTwpfAl1iuIRpC9IPB8,3456
-dtps_http/ergo_utils.py,sha256=NiHY7Th93zimK-DLT4KkEaFK_wMM9YgbU9uJBl3zf8o,1349
-dtps_http/exceptions.py,sha256=74bXD3KkuYxI5CVHsIt8FEqMaE3W4Z3sWVssp6MAq60,369
+dtps_http/__init__.py,sha256=WoxxqsLzKrewwQqPxcsPYJ6bAmOk4ycG7AflzYS0UAw,655
+dtps_http/blob_manager.py,sha256=L5VU08-5hf32qcdopzFA-LJmefqBn2RxJV3NG6oi9TQ,4861
+dtps_http/client.py,sha256=SurposVrv29qn3GAA7-VL6JPA6jDRNElARPtZpY0tUk,62663
+dtps_http/constants.py,sha256=1p5-Jywj4SvV4WR-Krx7agOjhHCbbt8cKiD3Ng_n-_8,3576
+dtps_http/ergo_utils.py,sha256=tVW797yywqleDm9f0yoo8pZXHk5yb-8gr3j9yJQjakI,1365
+dtps_http/exceptions.py,sha256=4w-Yrx-MedOytS_QIpNCiIZRQbFTjyjID-MO-JL_skw,420
 dtps_http/link_headers.py,sha256=ADp5tF-pKU1N7W3M4SISASYTTisL086lTHKYpwDPEo0,1672
-dtps_http/object_queue.py,sha256=yJSS5mAka0ULgwULZnrjA6FEWZWgF9WbRmyiPn0DfE8,10313
+dtps_http/object_queue.py,sha256=u7Qjn47RaCzv-PJubiufsRj_wTI0sZkp44C7EbWPRi8,10357
 dtps_http/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dtps_http/server.py,sha256=nWPaNYPoOkqEkQQqh7N5UoyeMp-Sdu0_zHejpJecId4,74898
+dtps_http/server.py,sha256=jrUyjTX7M-t2oVgSoK_CZnPUswnzp9YpyicwdJgRBPQ,75027
 dtps_http/server_start.py,sha256=fK1pNHPveSCeEw8AV5M6WfVqKHz4nyq4xW1tP9JZCtI,9695
-dtps_http/structures.py,sha256=G3V5zol5ROE0vwmgk9ciqYtZ3qV_5qk7mR9OBzuN9EQ,16233
+dtps_http/structures.py,sha256=GenzOEpycicy0DSh1OTfawZbcbKKRuN0NQHNJRDmHls,16304
 dtps_http/types.py,sha256=0izHqzwhIqABEFg6lPuf9-fzu8VvxjsukOOlepl9nhQ,3555
 dtps_http/types_of_source.py,sha256=qpq--U-xBYPWPKpGN1z8wq_uOk0oLBahW9Voz-A2NF0,21400
 dtps_http/urls.py,sha256=NmGcqCpanRrco1JhPQGNvn-rLG2jIQ9W7J2G9YyisGQ,4336
-dtps_http/utils.py,sha256=ER5mn_u1EVF0KHP34i-LsBRuWtkOVDcebooQlV6SozA,6114
+dtps_http/utils.py,sha256=V31fI0dQSMuG5UcWuQZcuSlol9oC92ZonN_bx6REHDI,6139
 dtps_http/utils_every_once_in_a_while.py,sha256=nvZsWa1dnK0i8bSkOciUw-VrLxMpT25QZ6pOcXQICig,838
-dtps_http_programs/__init__.py,sha256=f1W2LssjicOmQJ2ulwC8d9djFknf9kVvZS1Ykmlir0U,257
+dtps_http_programs/__init__.py,sha256=JICOhlo3COTc8ksiDvXkzsarDIQMovCljZDgCpOrgw4,257
 dtps_http_programs/dtps_listen.py,sha256=2T-CxSAqnC7mdT5AD-bsYqWBggPABefadL_TjxGrBR0,3671
 dtps_http_programs/dtps_proxy.py,sha256=luhDbyOQeFuQOeAXhIB8CjsYhjW8260rHVN2vVWKiTM,1721
 dtps_http_programs/dtps_send_continuous.py,sha256=M4QHRoAUrZ04Rshm11n-g4CUsEeDjvW_UpdRqUHccvo,1338
 dtps_http_programs/dtps_stats.py,sha256=oC8uEjPFhUN1soZ6wkyzmffPPRLuZxrjESsbqfVBN9A,3112
 dtps_http_programs/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 dtps_http_programs/server_clock.py,sha256=r7aJJjsXN6Gy26Iy6qw_gs0xQ7RbMlgJBcAhZYFZt7M,1789
-dtps_http_programs/test_memory.py,sha256=yPSyKWtflW1XiJP3CWZB79Svcw2l6wdu9KfcM7fiNAQ,4676
+dtps_http_programs/test_memory.py,sha256=pI1W8admZA3k7XpR-7q2R1eCuVUi71jW5A4xkFwUZGA,4682
 dtps_http_programs/test_memory_dashboard.py,sha256=MwdW9yT4wfNYpEzDLi9UaZRUvzuD39gfxbaMKth6YQ8,3267
-dtps_http_programs/test_memory_use.py,sha256=ctiStocnJJuysOpxsH1Fev81roVaADC3SMhIJcSZESE,5251
-static/favicon.png,sha256=6PxFTHHeynIHwf_FBPsoGbNsXB3-_TdYoem_McubXME,129
+dtps_http_programs/test_memory_use.py,sha256=CguYdI4kYFLj_jRmmzVzFEuBSBWA-zLxZMNAA6S9wt8,5257
+static/favicon.png,sha256=SuoDecEFzJG3RabXtOofSBcIPjDhKVLjFB0UX_LW4tI,1270
 static/send.js,sha256=_dvhwM61lpyrlIDd0-3xeJ59RCPgeLzBcMpeDlNqEms,7885
 static/style.css,sha256=hYKy8n6jh47vqXRg-ljM1x3Ket2rtMhH08TpOIHaW_s,1472
-dtps_http-1.1.1.dist-info/LICENSE.pdf,sha256=V1TBclYda54_miAikuVMwqHoWjwkjHw_yoF2zEqpc_k,75933
-dtps_http-1.1.1.dist-info/METADATA,sha256=7QPEqKMacN1Pv3YpQMKRT0Xn6faSvaaEKuddnAHhuDg,1001
-dtps_http-1.1.1.dist-info/WHEEL,sha256=FMvqSimYX_P7y0a7UY-_Mc83r5zkBZsCYPm7Lr0Bsq4,88
-dtps_http-1.1.1.dist-info/entry_points.txt,sha256=0f8h-Ls_gnf01ABr2FNt1iv2hZqrTfchBMIq-hJs6Uc,379
-dtps_http-1.1.1.dist-info/RECORD,,
+dtps_http-1.2.0.dist-info/LICENSE.pdf,sha256=V1TBclYda54_miAikuVMwqHoWjwkjHw_yoF2zEqpc_k,75933
+dtps_http-1.2.0.dist-info/METADATA,sha256=dxqCQfGCMomex4nFNIXuP2WSJhfv6NfJsfGEIooeX7U,1001
+dtps_http-1.2.0.dist-info/WHEEL,sha256=FMvqSimYX_P7y0a7UY-_Mc83r5zkBZsCYPm7Lr0Bsq4,88
+dtps_http-1.2.0.dist-info/entry_points.txt,sha256=0f8h-Ls_gnf01ABr2FNt1iv2hZqrTfchBMIq-hJs6Uc,379
+dtps_http-1.2.0.dist-info/RECORD,,
```

