# Comparing `tmp/seqspec-0.1.1-py3-none-any.whl.zip` & `tmp/seqspec-0.2.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,27 +1,28 @@
-Zip file size: 24411 bytes, number of entries: 25
--rw-r--r--  2.0 unx     2552 b- defN 23-Oct-31 21:51 seqspec/Assay.py
--rw-r--r--  2.0 unx     7053 b- defN 23-Nov-11 21:40 seqspec/Region.py
--rw-r--r--  2.0 unx       22 b- defN 23-Nov-28 14:28 seqspec/__init__.py
--rw-r--r--  2.0 unx     3174 b- defN 23-Nov-01 13:09 seqspec/main.py
--rw-r--r--  2.0 unx     5222 b- defN 23-Nov-11 22:08 seqspec/seqspec_check.py
+Zip file size: 31875 bytes, number of entries: 26
+-rw-r--r--  2.0 unx     3495 b- defN 24-Apr-17 22:34 seqspec/Assay.py
+-rw-r--r--  2.0 unx    11169 b- defN 24-Apr-17 22:34 seqspec/Region.py
+-rw-r--r--  2.0 unx       22 b- defN 24-Apr-17 22:39 seqspec/__init__.py
+-rw-r--r--  2.0 unx     3265 b- defN 23-Dec-18 15:31 seqspec/main.py
+-rw-r--r--  2.0 unx    10809 b- defN 24-Apr-17 22:34 seqspec/seqspec_check.py
 -rw-r--r--  2.0 unx     1075 b- defN 23-Oct-31 21:51 seqspec/seqspec_diff.py
--rw-r--r--  2.0 unx     1893 b- defN 23-Oct-31 21:51 seqspec/seqspec_find.py
+-rw-r--r--  2.0 unx     1898 b- defN 24-Apr-17 22:34 seqspec/seqspec_find.py
 -rw-r--r--  2.0 unx      797 b- defN 23-Oct-31 21:51 seqspec/seqspec_format.py
--rw-r--r--  2.0 unx     7967 b- defN 23-Nov-02 13:58 seqspec/seqspec_index.py
--rw-r--r--  2.0 unx      970 b- defN 23-Oct-31 22:04 seqspec/seqspec_info.py
--rw-r--r--  2.0 unx     3323 b- defN 23-Oct-31 21:51 seqspec/seqspec_init.py
--rw-r--r--  2.0 unx     3433 b- defN 23-Oct-31 21:51 seqspec/seqspec_modify.py
--rw-r--r--  2.0 unx     3025 b- defN 23-Nov-11 21:54 seqspec/seqspec_onlist.py
--rw-r--r--  2.0 unx     6601 b- defN 23-Oct-31 21:51 seqspec/seqspec_print.py
--rw-r--r--  2.0 unx     4215 b- defN 23-Nov-01 00:46 seqspec/seqspec_print_html.py
--rw-r--r--  2.0 unx     1409 b- defN 23-Oct-31 21:51 seqspec/seqspec_split.py
+-rw-r--r--  2.0 unx     5509 b- defN 23-Dec-18 15:28 seqspec/seqspec_genbank.py
+-rw-r--r--  2.0 unx     9405 b- defN 24-Apr-17 22:34 seqspec/seqspec_index.py
+-rw-r--r--  2.0 unx      972 b- defN 24-Apr-17 22:34 seqspec/seqspec_info.py
+-rw-r--r--  2.0 unx     3327 b- defN 24-Apr-17 22:34 seqspec/seqspec_init.py
+-rw-r--r--  2.0 unx     3432 b- defN 24-Apr-17 22:34 seqspec/seqspec_modify.py
+-rw-r--r--  2.0 unx     6450 b- defN 24-Apr-17 22:34 seqspec/seqspec_onlist.py
+-rw-r--r--  2.0 unx     9954 b- defN 24-Apr-17 22:34 seqspec/seqspec_print.py
+-rw-r--r--  2.0 unx     4229 b- defN 24-Apr-17 22:34 seqspec/seqspec_print_html.py
+-rw-r--r--  2.0 unx     1408 b- defN 24-Apr-17 22:34 seqspec/seqspec_split.py
 -rw-r--r--  2.0 unx      955 b- defN 23-Nov-01 13:10 seqspec/seqspec_version.py
--rw-r--r--  2.0 unx     1990 b- defN 23-Oct-31 21:51 seqspec/utils.py
--rw-r--r--  2.0 unx     4718 b- defN 23-Nov-11 21:32 seqspec/schema/seqspec.schema.json
--rw-r--r--  2.0 unx     1072 b- defN 23-Nov-28 14:29 seqspec-0.1.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     2778 b- defN 23-Nov-28 14:29 seqspec-0.1.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Nov-28 14:29 seqspec-0.1.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       46 b- defN 23-Nov-28 14:29 seqspec-0.1.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        8 b- defN 23-Nov-28 14:29 seqspec-0.1.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1993 b- defN 23-Nov-28 14:29 seqspec-0.1.1.dist-info/RECORD
-25 files, 66383 bytes uncompressed, 21221 bytes compressed:  68.0%
+-rw-r--r--  2.0 unx     5999 b- defN 24-Apr-17 22:34 seqspec/utils.py
+-rw-r--r--  2.0 unx     6785 b- defN 24-Apr-17 22:34 seqspec/schema/seqspec.schema.json
+-rw-r--r--  2.0 unx     1072 b- defN 24-Apr-17 22:40 seqspec-0.2.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     2870 b- defN 24-Apr-17 22:40 seqspec-0.2.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-17 22:40 seqspec-0.2.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       46 b- defN 24-Apr-17 22:40 seqspec-0.2.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        8 b- defN 24-Apr-17 22:40 seqspec-0.2.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2078 b- defN 24-Apr-17 22:40 seqspec-0.2.0.dist-info/RECORD
+26 files, 97121 bytes uncompressed, 28557 bytes compressed:  70.6%
```

## zipnote {}

```diff
@@ -18,14 +18,17 @@
 
 Filename: seqspec/seqspec_find.py
 Comment: 
 
 Filename: seqspec/seqspec_format.py
 Comment: 
 
+Filename: seqspec/seqspec_genbank.py
+Comment: 
+
 Filename: seqspec/seqspec_index.py
 Comment: 
 
 Filename: seqspec/seqspec_info.py
 Comment: 
 
 Filename: seqspec/seqspec_init.py
@@ -51,26 +54,26 @@
 
 Filename: seqspec/utils.py
 Comment: 
 
 Filename: seqspec/schema/seqspec.schema.json
 Comment: 
 
-Filename: seqspec-0.1.1.dist-info/LICENSE
+Filename: seqspec-0.2.0.dist-info/LICENSE
 Comment: 
 
-Filename: seqspec-0.1.1.dist-info/METADATA
+Filename: seqspec-0.2.0.dist-info/METADATA
 Comment: 
 
-Filename: seqspec-0.1.1.dist-info/WHEEL
+Filename: seqspec-0.2.0.dist-info/WHEEL
 Comment: 
 
-Filename: seqspec-0.1.1.dist-info/entry_points.txt
+Filename: seqspec-0.2.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: seqspec-0.1.1.dist-info/top_level.txt
+Filename: seqspec-0.2.0.dist-info/top_level.txt
 Comment: 
 
-Filename: seqspec-0.1.1.dist-info/RECORD
+Filename: seqspec-0.2.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## seqspec/Assay.py

```diff
@@ -1,87 +1,109 @@
 import yaml
-from seqspec.Region import Region
+from seqspec.Region import Region, Read
 from typing import List
 import json
 from . import __version__
 
 
 class Assay(yaml.YAMLObject):
     yaml_tag = "!Assay"
 
     def __init__(
         self,
-        assay: str,
-        sequencer: str,
+        assay_id: str,
         name: str,
         doi: str,
-        publication_date: str,
+        date: str,
         description: str,
         modalities: List[str],
         lib_struct: str,
-        assay_spec: List[Region],
+        sequence_protocol: str,
+        sequence_kit: str,
+        library_protocol: str,
+        library_kit: str,
+        sequence_spec: List[Read],
+        library_spec: List[Region],
         seqspec_version: str = __version__,
     ) -> None:
         super().__init__()
         self.seqspec_version = seqspec_version
-        self.assay = assay
-        self.sequencer = sequencer
+        self.assay_id = assay_id
         self.name = name
         self.doi = doi
-        self.publication_date = publication_date
+        self.date = date
         self.description = description
         self.modalities = modalities
         self.lib_struct = lib_struct
-        self.assay_spec = assay_spec
+        self.sequence_protocol = sequence_protocol
+        self.sequence_kit = sequence_kit
+        self.library_protocol = library_protocol
+        self.library_kit = library_kit
+        self.sequence_spec = sequence_spec
+        self.library_spec = library_spec
 
     def __repr__(self) -> str:
         d = {
             "seqspec_version": self.seqspec_version,
-            "assay": self.assay,
-            "sequencer": self.sequencer,
+            "assay_id": self.assay_id,
             "name": self.name,
             "doi": self.doi,
-            "publication_date": self.publication_date,
+            "date": self.date,
             "description": self.description,
             "modalities": self.modalities,
             "lib_struct": self.lib_struct,
-            "assay_spec": self.assay_spec,
+            "sequence_protocol": self.sequence_protocol,
+            "sequence_kit": self.sequence_kit,
+            "library_protocol": self.library_protocol,
+            "library_kit": self.library_kit,
+            "sequence_spec": self.sequence_spec,
+            "library_spec": self.library_spec,
         }
         return f"{d}"
 
     def to_dict(self):
         d = {
             "seqspec_version": self.seqspec_version,
-            "assay": self.assay,
-            "sequencer": self.sequencer,
+            "assay_id": self.assay_id,
             "name": self.name,
             "doi": self.doi,
-            "publication_date": self.publication_date,
+            "date": self.date,
             "description": self.description,
             "modalities": self.modalities,
             "lib_struct": self.lib_struct,
-            "assay_spec": [o.to_dict() for o in self.assay_spec],
+            "sequence_protocol": self.sequence_protocol,
+            "sequence_kit": self.sequence_kit,
+            "library_protocol": self.library_protocol,
+            "library_kit": self.library_kit,
+            "sequence_spec": [o.to_dict() for o in self.sequence_spec],
+            "library_spec": [o.to_dict() for o in self.library_spec],
         }
         return d
 
     def to_JSON(self):
         return json.dumps(self, default=lambda o: o.__dict__, sort_keys=False, indent=4)
 
     # note to_yaml is reserved for yaml.YAMLObject
     def to_YAML(self, fname: str):
         with open(fname, "w") as f:
             yaml.dump(self, f, sort_keys=False)
 
     def print_sequence(self):
-        for region in self.assay_spec:
+        for region in self.library_spec:
             print(region.get_sequence(), end="")
         print("\n", end="")
 
     def update_spec(self):
-        for r in self.assay_spec:
+        for r in self.library_spec:
             r.update_attr()
 
-    def get_modality(self, modality):
-        return self.assay_spec[self.modalities.index(modality)]
+    def get_libspec(self, modality):
+        return self.library_spec[self.modalities.index(modality)]
+
+    def get_seqspec(self, modality):
+        return [r for r in self.sequence_spec if r.modality == modality]
+
+    def get_read(self, read_id):
+        return [r for r in self.sequence_spec if r.read_id == read_id][0]
 
     def list_modalities(self):
         return self.modalities
```

## seqspec/Region.py

```diff
@@ -70,18 +70,18 @@
     def update_attr(self):
         if self.regions:
             for idx, r in enumerate(self.regions):
                 r.update_attr()
 
         self.sequence = self.get_sequence()
         self.min_len, self.max_len = self.get_len()
-        if self.sequence_type == "random" or self.sequence_type == "onlist":
-            self.sequence = "X" * self.min_len
+        if self.sequence_type == "random":
+            self.sequence = "X" * self.max_len
         if self.sequence_type == "onlist":
-            self.sequence = "N" * self.min_len
+            self.sequence = "N" * self.max_len
         return
 
     def __repr__(self) -> str:
         d = {
             "region_id": self.region_id,
             "region_type": self.region_type,
             "name": self.name,
@@ -125,22 +125,22 @@
         if self.region_id == region_id:
             found.append(self)
         if self.regions:
             for r in self.regions:
                 found = r.get_region_by_id(region_id, found)
         return found
 
-    def get_region_by_type(self, region_type, found=[]):
+    def get_region_by_region_type(self, region_type, found=[]):
         if not found:
             found = []
         if self.region_type == region_type:
             found.append(self)
         if self.regions:
             for r in self.regions:
-                found = r.get_region_by_type(region_type, found)
+                found = r.get_region_by_region_type(region_type, found)
         return found
 
     def get_onlist_regions(self, found=[]):
         if not found:
             found = []
         if self.onlist is not None:
             found.append(self)
@@ -218,14 +218,131 @@
                 target_region.sequence = sequence
             if min_len:
                 target_region.min_len = min_len
             if max_len:
                 target_region.max_len = max_len
         return
 
+    def reverse(self):
+        if self.regions:
+            # reverse the list of sub regions
+            for r in self.regions[::-1]:
+                r.reverse()
+        else:
+            # reverse the actual sequence
+            self.sequence = self.sequence[::-1]
+        return
+
+    def complement(self):
+        if self.regions:
+            for r in self.regions:
+                r.complement()
+        else:
+            self.sequence = complement_sequence(self.sequence)
+
+
+def complement_nucleotide(nucleotide):
+    complements = {
+        "A": "T",
+        "T": "A",
+        "G": "C",
+        "C": "G",
+        "R": "Y",
+        "Y": "R",
+        "S": "S",
+        "W": "W",
+        "K": "M",
+        "M": "K",
+        "B": "V",
+        "D": "H",
+        "V": "B",
+        "H": "D",
+        "N": "N",
+        "X": "X",
+    }
+    return complements.get(
+        nucleotide, "N"
+    )  # Default to 'N' if nucleotide is not recognized
+
+
+def complement_sequence(sequence):
+    return "".join(complement_nucleotide(n) for n in sequence.upper())
+
+
+class RegionCoordinate(Region):
+    def __init__(
+        self,
+        region: Region,
+        start: int = 0,
+        stop: int = 0,
+    ):
+        super().__init__(
+            region.region_id,
+            region.region_type,
+            region.name,
+            region.sequence_type,
+            region.sequence,
+            region.min_len,
+            region.max_len,
+            region.onlist,
+            region.regions,
+        )
+        self.start = start
+        self.stop = stop
+
+    def __repr__(self):
+        return f"RegionCoordinate {self.name} [{self.region_type}]: ({self.start}, {self.stop})"
+
+    def __str__(self):
+        return f"RegionCoordinate {self.name} [{self.region_type}]: ({self.start}, {self.stop})"
+
+    def __eq__(self, other):
+        return self.start == other.start and self.stop == other.stop
+
+
+def project_regions_to_coordinates(
+    regions: List[Region], rcs: List[RegionCoordinate] = []
+) -> List[RegionCoordinate]:
+    if not rcs:
+        rcs = []
+    prev = 0
+    for r in regions:
+        nxt = prev + r.max_len
+        rc = RegionCoordinate(r, prev, nxt)
+        rcs.append(rc)
+        prev = nxt
+    return rcs
+
+
+def itx_read(
+    region_coordinates: List[RegionCoordinate], read_start: int, read_stop: int
+):
+    # return a list of region_coordinates intersect with read start/stop
+    new_rcs = []
+
+    for idx, rc in enumerate(region_coordinates):
+        # read start after rc ends, ignore
+        if read_start >= rc.stop:
+            continue
+        # read stop before rc starts, ignore
+        if read_stop <= rc.start:
+            continue
+
+        # all region_coordinates now have read start or stop in the rc
+
+        # read start in rc, update start
+        if read_start >= rc.start:
+            rc.start = read_start
+        # read stop in rc, update stop
+        if read_stop < rc.stop:
+            rc.stop = read_stop
+        new_rcs.append(rc)
+
+    return new_rcs
+
 
 class Onlist(yaml.YAMLObject):
     yaml_tag = "!Onlist"
 
     def __init__(self, filename: str, md5: str, location: str) -> None:
         super().__init__()
         self.filename = filename
@@ -243,7 +360,54 @@
     def to_dict(self):
         d = {
             "filename": self.filename,
             "location": self.location,
             "md5": self.md5,
         }
         return d
+
+
+class Read(yaml.YAMLObject):
+    yaml_tag = "!Read"
+
+    def __init__(
+        self,
+        read_id: str,
+        name: str,
+        modality: str,
+        primer_id: str,
+        min_len: int,
+        max_len: int,
+        strand: str,
+    ) -> None:
+        super().__init__()
+        self.read_id = read_id
+        self.name = name
+        self.modality = modality
+        self.primer_id = primer_id
+        self.min_len = min_len
+        self.max_len = max_len
+        self.strand = strand
+
+    def __repr__(self) -> str:
+        d = {
+            "read_id": self.read_id,
+            "name": self.name,
+            "modality": self.modality,
+            "primer_id": self.primer_id,
+            "min_len": self.min_len,
+            "max_len": self.max_len,
+            "strand": self.strand,
+        }
+        return f"{d}"
+
+    def to_dict(self):
+        d = {
+            "read_id": self.read_id,
+            "name": self.name,
+            "modality": self.modality,
+            "primer_id": self.primer_id,
+            "min_len": self.min_len,
+            "max_len": self.max_len,
+            "strand": self.strand,
+        }
+        return d
```

## seqspec/__init__.py

```diff
@@ -1 +1 @@
-__version__ = "0.1.1"
+__version__ = "0.2.0"
```

## seqspec/main.py

```diff
@@ -2,15 +2,15 @@
 import argparse
 import sys
 from .seqspec_format import setup_format_args, validate_format_args
 from .seqspec_print import setup_print_args, validate_print_args
 from .seqspec_check import setup_check_args, validate_check_args
 from .seqspec_find import setup_find_args, validate_find_args
 
-# from .seqspec_convert import setup_convert_args, validate_convert_args
+from .seqspec_genbank import setup_genbank_args, validate_genbank_args
 from .seqspec_modify import setup_modify_args, validate_modify_args
 from .seqspec_index import setup_index_args, validate_index_args
 from .seqspec_info import setup_info_args, validate_info_args
 
 from .seqspec_split import setup_split_args, validate_split_args
 from .seqspec_init import setup_init_args, validate_init_args
 from .seqspec_onlist import setup_onlist_args, validate_onlist_args
@@ -35,14 +35,15 @@
     )
 
     # Setup the arguments for all subcommands
     command_to_parser = {
         "check": setup_check_args(subparsers),
         "find": setup_find_args(subparsers),
         "format": setup_format_args(subparsers),
+        "genbank": setup_genbank_args(subparsers),
         "index": setup_index_args(subparsers),
         "info": setup_info_args(subparsers),
         "init": setup_init_args(subparsers),
         "modify": setup_modify_args(subparsers),
         "onlist": setup_onlist_args(subparsers),
         "print": setup_print_args(subparsers),
         "split": setup_split_args(subparsers),
@@ -72,13 +73,14 @@
         "index": validate_index_args,
         "info": validate_info_args,
         "init": validate_init_args,
         "modify": validate_modify_args,
         "onlist": validate_onlist_args,
         "split": validate_split_args,
         "version": validate_version_args,
+        "genbank": validate_genbank_args,
     }
     COMMAND_TO_FUNCTION[sys.argv[1]](parser, args)
 
 
 if __name__ == "__main__":
     main()
```

## seqspec/seqspec_check.py

```diff
@@ -61,28 +61,28 @@
             f"[error {idx}] modalities [{', '.join(spec.modalities)}] are not unique"
         )
         idx += 1
 
     # check that region_ids of the first level of the spec correspond to the modalities
     # one for each modality
     modes = spec.modalities
-    rgns = spec.assay_spec
+    rgns = spec.library_spec
     for r in rgns:
         rid = r.region_id
         if rid not in modes:
             errors.append(
                 f"[error {idx}] region_id '{rid}' of the first level of the spec does not correspond to a modality [{', '.join(modes)}]"
             )
             idx += 1
 
     # get all of the onlist files in the spec and check that they exist relative to the path of the spec
     modes = spec.modalities
     olrgns = []
     for m in modes:
-        olrgns += [i.onlist for i in spec.get_modality(m).get_onlist_regions()]
+        olrgns += [i.onlist for i in spec.get_libspec(m).get_onlist_regions()]
 
     # check paths relative to spec_fn
     for ol in olrgns:
         if ol.location == "local":
             if ol.filename[:-3] == ".gz":
                 check = path.join(path.dirname(spec_fn), ol.filename[:-3])
                 if not path.exists(check):
@@ -99,45 +99,176 @@
             if not file_exists(ol.filename):
                 errors.append(f"[error {idx}] {ol.filename} does not exist")
                 idx += 1
 
     # get all of the regions with type fastq in the spec and check that those files exist relative to the path of the spec
     fqrgns = []
     for m in modes:
-        fqrgns += [i for i in spec.get_modality(m).get_region_by_type("fastq")]
-        fqrgns += [i for i in spec.get_modality(m).get_region_by_type("fastq_link")]
+        fqrgns += [i for i in spec.get_libspec(m).get_region_by_region_type("fastq")]
+        fqrgns += [
+            i for i in spec.get_libspec(m).get_region_by_region_type("fastq_link")
+        ]
     for fqrgn in fqrgns:
         if fqrgn.region_type == "fastq":
             check = path.join(path.dirname(spec_fn), fqrgn.region_id)
             if not path.exists(check):
                 errors.append(f"[error {idx}] {fqrgn.region_id} does not exist")
                 idx += 1
         elif fqrgn.region_type == "fastq_link":
             # ping the link with a simple http request to check if the file exists at that URI
             if not file_exists(fqrgn.region_id):
                 errors.append(f"[error {idx}] {fqrgn.region_id} does not exist")
                 idx += 1
 
+    # read ids should be unique
+    read_ids = set()
+    for read in spec.sequence_spec:
+        if read.read_id in read_ids:
+            errors.append(
+                f"[error {idx}] read_id '{read.read_id}' is not unique across all reads"
+            )
+            idx += 1
+        else:
+            read_ids.add(read.read_id)
+
+    # iterate through reads in sequence_spec and check that the fastq files exist
+    for read in spec.sequence_spec:
+        check = path.join(path.dirname(spec_fn), read.read_id)
+        if not path.exists(check):
+            errors.append(f"[error {idx}] {read.read_id} file does not exist")
+            idx += 1
+
+    # check that the primer ids, strand tuple pairs are unique across all reads
+    primer_strand_pairs = set()
+    for read in spec.sequence_spec:
+        if (read.primer_id, read.strand) in primer_strand_pairs:
+            errors.append(
+                f"[error {idx}] primer_id '{read.primer_id}' and strand '{read.strand}' tuple is not unique across all reads"
+            )
+            idx += 1
+        else:
+            primer_strand_pairs.add((read.primer_id, read.strand))
+
     # TODO add option to check md5sum
 
     # check that the region_id is unique across all regions
     rgn_ids = set()
     for m in modes:
-        for rgn in spec.get_modality(m).get_leaves():
+        for rgn in spec.get_libspec(m).get_leaves():
             if rgn.region_id in rgn_ids:
                 errors.append(
                     f"[error {idx}] region_id '{rgn.region_id}' is not unique across all regions"
                 )
                 idx += 1
             else:
                 rgn_ids.add(rgn.region_id)
 
-    # check that sequence length is the same as min_length
+    # check that the modality is in the reads
+    for read in spec.sequence_spec:
+        if read.modality not in modes:
+            errors.append(
+                f"[error {idx}] '{read.read_id}' modality '{read.modality}' does not exist in the modalities"
+            )
+            idx += 1
+
+    # check that the unique primer ids exist as a region id in the library_spec
+    for read in spec.sequence_spec:
+        if read.primer_id not in rgn_ids:
+            errors.append(
+                f"[error {idx}] '{read.read_id}' primer_id '{read.primer_id}' does not exist in the library_spec"
+            )
+            idx += 1
+
+    # NOTE: this is a strong assumption that may be relaxed in the future
+    # check that the primer id for each read is in the leaves of the spec for that modality
+    for read in spec.sequence_spec:
+        mode = spec.get_libspec(read.modality)
+        leaves = mode.get_leaves()
+        if read.primer_id not in [i.region_id for i in leaves]:
+            errors.append(
+                f"[error {idx}] '{read.read_id}' primer_id '{read.primer_id}' does not exist as an atomic region in the library_spec for modality '{read.modality}'"
+            )
+            idx += 1
+
+    # check that the max read len is not longer than the max len of the lib spec after the primer
+    # for read in spec.sequence_spec:
+    #     mode = spec.get_libspec(read.modality)
+    #     leaves = mode.get_leaves()
+    #     idx = [i.region_id for i in leaves].index(read.primer_id)
+
+    # if a region has a sequence type "fixed" then it should not contain subregions
+    # if a region has a sequence type "joiend" then it should contain subregions
+    # if a region has a sequence type "random" then it should not contain subregions and should be all X's
+    # if a region has a sequence type "onlist" then it should have an onlist object
+    def seqtype_check(rgn, errors, idx):
+        # this is a recursive function that iterates through all regions and checks the sequence type
+        if rgn.sequence_type == "fixed" and rgn.regions:
+            errors.append(
+                f"[error {idx}] '{rgn.region_id}' sequence_type is 'fixed' and contains subregions"
+            )
+            idx += 1
+        if rgn.sequence_type == "joined" and not rgn.regions:
+            errors.append(
+                f"[error {idx}] '{rgn.region_id}' sequence_type is 'joined' and does not contain subregions"
+            )
+            idx += 1
+        if rgn.sequence_type == "random" and rgn.regions:
+            errors.append(
+                f"[error {idx}] '{rgn.region_id}' sequence_type is 'random' and contains subregions"
+            )
+            idx += 1
+        if rgn.sequence_type == "random" and rgn.sequence != "X" * rgn.max_len:
+            errors.append(
+                f"[error {idx}] '{rgn.region_id}' sequence_type is 'random' and sequence is not all X's"
+            )
+            idx += 1
+        if rgn.sequence_type == "onlist" and not rgn.onlist:
+            errors.append(
+                f"[error {idx}] '{rgn.region_id}' sequence_type is 'onlist' and does not have an onlist object"
+            )
+            idx += 1
+        if rgn.regions:
+            for r in rgn.regions:
+                errors, idx = seqtype_check(r, errors, idx)
+        return (errors, idx)
+
     for m in modes:
-        for rgn in spec.get_modality(m).get_leaves():
-            if rgn.sequence and len(rgn.sequence) < rgn.min_len:
-                errors.append(
-                    f"[error {idx}] '{rgn.region_id}' sequence '{rgn.sequence}' length '{len(rgn.sequence)}' is less than min_len '{rgn.min_len}'"
-                )
-                idx += 1
+        for rgn in [spec.get_libspec(m)]:
+            errors, idx = seqtype_check(rgn, errors, idx)
+
+    # check the lengths of every region against the max_len, using a recursive function
+    def len_check(rgn, errors, idx):
+        if rgn.regions:
+            for r in rgn.regions:
+                errors, idx = len_check(r, errors, idx)
+        if rgn.max_len < rgn.min_len:
+            errors.append(
+                f"[error {idx}] '{rgn.region_id}' max_len is less than min_len"
+            )
+            idx += 1
+        return (errors, idx)
+
+    for m in modes:
+        for rgn in [spec.get_libspec(m)]:
+            errors, idx = len_check(rgn, errors, idx)
+
+    # check that the length of the sequence is equal to the max_len using a recursive function
+    # an assumption in the code and spec is that the displayed sequence is equal to the max_len
+    def seq_len_check(rgn, errors, idx):
+        if rgn.regions:
+            for r in rgn.regions:
+                errors, idx = seq_len_check(r, errors, idx)
+        if rgn.sequence and (
+            len(rgn.sequence) < rgn.min_len or len(rgn.sequence) > rgn.max_len
+        ):
+            # noqa
+            errors.append(
+                f"[error {idx}] '{rgn.region_id}' sequence '{rgn.sequence}' has length {len(rgn.sequence)}, expected range ({rgn.min_len}, {rgn.max_len})"
+            )
+            idx += 1
+        return (errors, idx)
+
+    for m in modes:
+        for rgn in [spec.get_libspec(m)]:
+            errors, idx = seq_len_check(rgn, errors, idx)
 
     return errors
```

## seqspec/seqspec_find.py

```diff
@@ -64,16 +64,16 @@
         with open(o, "w") as f:
             yaml.dump(regions, f, sort_keys=False)
     else:
         print(yaml.dump(regions, sort_keys=False))
 
 
 def run_find(spec: Assay, modality: str, region_id: str):
-    m = spec.get_modality(modality)
+    m = spec.get_libspec(modality)
     regions = m.get_region_by_id(region_id)
     return regions
 
 
 def run_find_by_type(spec: Assay, modality: str, region_type: str):
-    m = spec.get_modality(modality)
-    regions = m.get_region_by_type(region_type)
+    m = spec.get_libspec(modality)
+    regions = m.get_region_by_region_type(region_type)
     return regions
```

## seqspec/seqspec_index.py

```diff
@@ -1,20 +1,21 @@
-from seqspec.utils import load_spec, get_cuts
+from seqspec.utils import load_spec, map_read_id_to_regions
 from seqspec.seqspec_find import run_find
 from collections import defaultdict
 from typing import Dict, List, Tuple
 from argparse import SUPPRESS
 import os
+from seqspec.Region import RegionCoordinate, project_regions_to_coordinates, itx_read
 
 
 def setup_index_args(parser):
     subparser = parser.add_parser(
         "index",
-        description="index regions in a seqspec file",
-        help="index regions in a seqspec file",
+        description="index reads or regions in a seqspec file",
+        help="index reads or regions in a seqspec file",
     )
     subparser_required = subparser.add_argument_group("required arguments")
     subparser.add_argument("yaml", help="Sequencing specification yaml file")
     subparser.add_argument(
         "-o",
         metavar="OUT",
         help=("Path to output file"),
@@ -39,24 +40,35 @@
         choices=["chromap", "kb", "seqkit", "simpleaf", "starsolo", "tab", "zumis"],
     )
 
     subparser.add_argument(
         "--rev", help="Returns 3'->5' region order", action="store_true"
     )
 
+    # boolean to indicate specifying a region or a read
+    subparser.add_argument(
+        "--region",
+        help="Specify a region",
+        action="store_true",
+    )
     subparser_required.add_argument(
         "-m",
         metavar="MODALITY",
         help=("Modality"),
         type=str,
         default=None,
         required=True,
     )
     subparser_required.add_argument(
-        "-r", metavar="REGION", help=("Region"), type=str, default=None, required=True
+        "-r",
+        metavar="READ or REGION",
+        help=("Read or Region"),
+        type=str,
+        default=None,
+        required=True,
     )
 
     return subparser
 
 
 def validate_index_args(parser, args):
     # if everything is valid the get_index
@@ -65,213 +77,237 @@
     m = args.m
     r = args.r
     t = args.t
     o = args.o
     s = args.s
     rev = args.rev
 
+    rgn = args.region
+
     # load spec
     spec = load_spec(fn)
-    rgns = r.split(",")
-    # regions can be paths, take the basename of the path, use os
+    rds = r.split(",")
+    # reads can be paths, take the basename of the path, use os
 
-    rgns = [os.path.basename(r) for r in rgns]
+    rds = [os.path.basename(r) for r in rds]
 
-    x = run_index(spec, m, rgns, fmt=t, rev=rev, subregion_type=s)
+    x = run_index(spec, m, rds, fmt=t, rev=rev, region=rgn, subregion_type=s)
 
     # post processing
     if o:
         with open(o, "w") as f:
             print(x, file=f)
     else:
         print(x)
     return
 
 
-def run_index(spec, modality, regions, fmt="tab", rev=False, subregion_type=None):
+def run_index(
+    spec, modality, reads, fmt="tab", rev=False, region=False, subregion_type=None
+):
     FORMAT = {
         "chromap": format_chromap,
         "kb": format_kallisto_bus,
         "seqkit": format_seqkit_subseq,
         "simpleaf": format_simpleaf,
         "starsolo": format_starsolo,
         "tab": format_tab,
         "zumis": format_zumis,
     }
     indices = []
-    for r in regions:
-        index = get_index(spec, modality, r, rev=rev)
-        indices.append({r: index})
+    for r in reads:
+        if region:
+            index = get_index(spec, modality, r, rev=rev)
+        else:
+            index = get_index_by_primer(spec, modality, r)
+        indices.append(index)
     return FORMAT[fmt](indices, subregion_type)
 
 
+# TODO: modify to use RegionCoordinate object
 def get_index_by_type(
     spec, modality, region_id, rev=False
 ) -> Dict[str, List[Tuple[int, int]]]:
     rid = region_id
     # run function
     index = defaultdict(list)
     regions = run_find(spec, modality, rid)
     leaves = regions[0].get_leaves()
     if rev:
         leaves.reverse()
-    cuts = get_cuts(leaves)
+    cuts = project_regions_to_coordinates(leaves)
+
+    # index is a legacy data structure, todo fix
+    for c in cuts:
+        index[c.start, c.stop] = c.region_type
 
     # groupby requested region
     for idx, l in enumerate(leaves):
         t = l.region_type
         c = cuts[idx]
 
         index[t].extend([c])
     return index
 
 
-def get_index(spec, modality, region_id, rev=False) -> Dict[Tuple[int, int], str]:
+def get_index(
+    spec, modality, region_id, rev=False
+) -> Dict[str, List[RegionCoordinate]]:
     rid = region_id
-    # run function
-    index = defaultdict()
     regions = run_find(spec, modality, rid)
     leaves = regions[0].get_leaves()
     if rev:
         leaves.reverse()
-    cuts = get_cuts(leaves)
+    cuts = project_regions_to_coordinates(leaves)
 
-    for idx, l in enumerate(leaves):
-        t = l.region_type
-        c = cuts[idx]
-        index[c] = t
+    return {region_id: cuts}
 
-    return index
+
+def get_index_by_primer(
+    spec, modality: str, read_id: str
+) -> Dict[str, List[RegionCoordinate]]:  # noqa
+    # this manages the strandedness internally
+    (read, rgns) = map_read_id_to_regions(spec, modality, read_id)
+
+    # get the cuts for all of the atomic elements (tuples of 0-indexed start stop)
+    rcs = project_regions_to_coordinates(rgns)
+
+    new_rcs = itx_read(rcs, 0, read.max_len)
+
+    return {read_id: new_rcs}
 
 
 def format_kallisto_bus(indices, subregion_type=None):
     bcs = []
     umi = []
     feature = []
     for idx, region in enumerate(indices):
-        for rgn, index in region.items():
-            for k, v in index.items():
-                if v.upper() == "BARCODE":
-                    bcs.append(f"{idx},{k[0]},{k[1]}")
-                elif v.upper() == "UMI":
-                    umi.append(f"{idx},{k[0]},{k[1]}")
+        for rgn, cuts in region.items():
+            for cut in cuts:
+                if cut.region_type.upper() == "BARCODE":
+                    bcs.append(f"{idx},{cut.start},{cut.stop}")
+                elif cut.region_type.upper() == "UMI":
+                    umi.append(f"{idx},{cut.start},{cut.stop}")
                 elif (
-                    v.upper() == "CDNA"
-                    or v.upper() == "GDNA"
-                    or v.upper() == "PROTEIN"
-                    or v.upper() == "TAG"
+                    cut.region_type.upper() == "CDNA"
+                    or cut.region_type.upper() == "GDNA"
+                    or cut.region_type.upper() == "PROTEIN"
+                    or cut.region_type.upper() == "TAG"
                 ):
-                    feature.append(f"{idx},{k[0]},{k[1]}")
+                    feature.append(f"{idx},{cut.start},{cut.stop}")
     if len(umi) == 0:
         umi.append("-1,-1,-1")
     if len(bcs) == 0:
         bcs.append("-1,-1,-1")
 
     x = ",".join(bcs) + ":" + ",".join(umi) + ":" + ",".join(feature)
     return x
 
 
 # this one should only return one string
+# TODO: return to this
 def format_seqkit_subseq(indices, subregion_type=None):
     # The x string format is start:stop (1-indexed)
     # x = ""
     # region = indices[0]
     # # need to get the right start position
     x = ""
     region = indices[0]
-    for rgn, index in region.items():
-        for k, v in index.items():
-            if v == subregion_type:
-                x = f"{k[0]+1}:{k[1]}\n"
+    for rgn, cuts in region.items():
+        for cut in cuts:
+            if cut.region_type == subregion_type:
+                x = f"{cut.start+1}:{cut.stop}\n"
 
     return x
 
 
 def format_tab(indices, subregion_type=None):
     x = ""
     for idx, region in enumerate(indices):
-        for rgn, index in region.items():
-            for k, v in index.items():
-                x += f"{rgn}\t{v}\t{k[0]}\t{k[1]}\n"
+        for rgn, cuts in region.items():
+            for cut in cuts:
+                x += f"{rgn}\t{cut.name}\t{cut.region_type}\t{cut.start}\t{cut.stop}\n"
 
     return x[:-1]
 
 
 def format_starsolo(indices, subregion_type=None):
     bcs = []
     umi = []
     cdna = []
     for idx, region in enumerate(indices):
-        for rgn, index in region.items():
-            for k, v in index.items():
-                if v.upper() == "BARCODE":
-                    bcs.append(f"--soloCBstart {k[0] + 1} --soloCBlen {k[1]}")
-                elif v.upper() == "UMI":
-                    umi.append(f"--soloUMIstart {k[0] + 1} --soloUMIlen {k[1] - k[0]}")
-                elif v.upper() == "CDNA":
-                    cdna.append(f"{k[0]},{k[1]}")
+        for rgn, cuts in region.items():
+            for cut in cuts:
+                if cut.region_type.upper() == "BARCODE":
+                    bcs.append(f"--soloCBstart {cut.start + 1} --soloCBlen {cut.stop}")
+                elif cut.region_type.upper() == "UMI":
+                    umi.append(
+                        f"--soloUMIstart {cut.start + 1} --soloUMIlen {cut.stop - cut.start}"
+                    )
+                elif cut.region_type.upper() == "CDNA":
+                    cdna.append(f"{cut.start},{cut.stop}")
     x = f"--soloType CB_UMI_Simple {bcs[0]} {umi[0]}"
     return x
 
 
 def format_simpleaf(indices, subregion_type=None):
     x = ""
     xl = []
     for idx, region in enumerate(indices):
         fn = idx
         x = f"{fn+1}{{"
-        for rgn, index in region.items():
-            for k, v in index.items():
-                if v.upper() == "BARCODE":
-                    x += f"b[{k[1]-k[0]}]"
-                elif v.upper() == "UMI":
-                    x += f"u[{k[1]-k[0]}]"
-                elif v.upper() == "CDNA":
-                    x += f"r[{k[1] - k[0]}]"
+        for rgn, cuts in region.items():
+            for cut in cuts:
+                if cut.region_type.upper() == "BARCODE":
+                    x += f"b[{cut.stop-cut.start}]"
+                elif cut.region_type.upper() == "UMI":
+                    x += f"u[{cut.stop-cut.start}]"
+                elif cut.region_type.upper() == "CDNA":
+                    x += f"r[{cut.stop - cut.start}]"
             x += "x:}"
         xl.append(x)
     return "".join(xl)
 
 
 def format_zumis(indices, subregion_type=None):
     xl = []
     for idx, region in enumerate(indices):
         x = ""
-        for rgn, index in region.items():
-            for k, v in index.items():
-                if v.upper() == "BARCODE":
-                    x += f"- BCS({k[0] + 1}-{k[1]})\n"
-                elif v.upper() == "UMI":
-                    x += f"- UMI({k[0] + 1}-{k[1]})\n"
-                elif v.upper() == "CDNA":
-                    x += f"- cDNA({k[0] + 1}-{k[1]})\n"
+        for rgn, cuts in region.items():
+            for cut in cuts:
+                if cut.region_type.upper() == "BARCODE":
+                    x += f"- BCS({cut.start + 1}-{cut.stop})\n"
+                elif cut.region_type.upper() == "UMI":
+                    x += f"- UMI({cut.start + 1}-{cut.stop})\n"
+                elif cut.region_type.upper() == "CDNA":
+                    x += f"- cDNA({cut.start + 1}-{cut.stop})\n"
         xl.append(x)
 
     return "\n".join(xl)[:-1]
 
 
 def format_chromap(indices, subregion_type=None):
     bc_fqs = []
     bc_str = []
     gdna_fqs = []
     gdna_str = []
     for idx, region in enumerate(indices):
-        for rgn, index in region.items():
-            for k, v in index.items():
-                if v.upper() == "BARCODE":
+        for rgn, cuts in region.items():
+            for cut in cuts:
+                if cut.region_type.upper() == "BARCODE":
                     bc_fqs.append(rgn)
-                    bc_str.append(f"bc:{k[0]}:{k[1]}")
+                    bc_str.append(f"bc:{cut.start}:{cut.stop}")
                     pass
-                elif v.upper() == "GDNA":
+                elif cut.region_type.upper() == "GDNA":
                     gdna_fqs.append(rgn)
-                    gdna_str.append(f"{k[0]}:{k[1]}")
+                    gdna_str.append(f"{cut.start}:{cut.stop}")
     if len(set(bc_fqs)) > 1:
-        raise "chromap only supports barcodes from one fastq"
+        raise Exception("chromap only supports barcodes from one fastq")
     if len(set(gdna_fqs)) > 2:
-        raise "chromap only supports genomic dna from two fastqs"
+        raise Exception("chromap only supports genomic dna from two fastqs")
 
     barcode_fq = bc_fqs[0]
     read1_fq = list(set(gdna_fqs))[0]
     read2_fq = list(set(gdna_fqs))[1]
     read_str = ",".join([f"r{idx}:{ele}" for idx, ele in enumerate(gdna_str, 1)])
     bc_str = ",".join(bc_str)
```

## seqspec/seqspec_info.py

```diff
@@ -34,9 +34,9 @@
     else:
         print(json.dumps(info, sort_keys=False, indent=4))
 
 
 def run_info(spec):
     # return json of the Assay object
     info = spec.to_dict()
-    del info["assay_spec"]
+    del info["library_spec"]
     return info
```

## seqspec/seqspec_init.py

```diff
@@ -50,15 +50,15 @@
         )
 
     # load in two specs
     spec = run_init(name, tree[0].descendants)
     spec.to_YAML(o)
 
 
-# takes in assay_spec list of nodes
+# takes in library_spec list of nodes
 def run_init(name: str, tree: List[newick.Node]):
     # make regions for each fastq
     # make region for each modality
     # add fastq regions to modality regions
     # add modality regions to assay
     rgns = []
     mnames = []
@@ -72,15 +72,15 @@
         sequencer="",
         name=name,
         doi="",
         publication_date="",
         description="",
         modalities=mnames,
         lib_struct="",
-        assay_spec=rgns,
+        library_spec=rgns,
     )
 
     return assay
 
 
 # nw = "((barcode,umi)r1.fastq.gz,(cdna)r2.fastq.gz)rna;"
 # wn = "rna(r1.fastq.gz(barcode,umi),r1.fastq.gz(cdna));"
```

## seqspec/seqspec_modify.py

```diff
@@ -131,15 +131,15 @@
     region_type,
     name,
     sequence_type,
     sequence,
     min_len,
     max_len,
 ):
-    spec.get_modality(modality).update_region_by_id(
+    spec.get_libspec(modality).update_region_by_id(
         target_region,
         region_id,
         region_type,
         name,
         sequence_type,
         sequence,
         min_len,
```

## seqspec/seqspec_onlist.py

```diff
@@ -1,13 +1,15 @@
 from seqspec.Assay import Assay
-from seqspec.utils import load_spec
-from seqspec.seqspec_find import run_find_by_type
+from seqspec.Region import project_regions_to_coordinates, itx_read, Onlist
+from seqspec.utils import load_spec, map_read_id_to_regions
+from seqspec.seqspec_find import run_find_by_type, run_find
 import os
-from seqspec.utils import read_list
+from seqspec.utils import read_list, find_onlist_file
 import itertools
+from typing import List
 
 
 def setup_onlist_args(parser):
     subparser = parser.add_parser(
         "onlist",
         description="get onlist file for specific region",
         help="get onlist file for specific regions",
@@ -17,84 +19,186 @@
     subparser.add_argument(
         "-o",
         metavar="OUT",
         help=("Path to output file"),
         type=str,
         default=None,
     )
+    format_choices = ["read", "region", "region-type"]
+    subparser.add_argument(
+        "-s",
+        metavar="SPECOBJECT",
+        type=str,
+        default="read",
+        choices=format_choices,
+        help=f"Type of spec object ({', '.join(format_choices)}), default: region",
+    )
     subparser_required.add_argument(
         "-m",
         metavar="MODALITY",
         help=("Modality"),
         type=str,
         default=None,
         required=True,
     )
     subparser_required.add_argument(
-        "-r", metavar="REGION", help=("Region"), type=str, default=None, required=False
+        "-r",
+        metavar="READ or REGION",
+        help=("Read or Region"),
+        type=str,
+        default=None,
+        required=False,
+    )
+    format_choices = ["product", "multi"]
+    subparser.add_argument(
+        "-f",
+        metavar="FORMAT",
+        type=str,
+        default="product",
+        choices=format_choices,
+        help=f"Format for combining multiple onlists ({', '.join(format_choices)}), default: product",
     )
     subparser.add_argument("--list", action="store_true", help=("List onlists"))
     return subparser
 
 
 def validate_onlist_args(parser, args):
     # get paramters
     fn = args.yaml
     m = args.m
     r = args.r
+    f = args.f
     # TODO: if onlist is a link, download. also fix output path
     # o = args.o
     # load spec
     spec = load_spec(fn)
     # if number of barcodes > 1 then we need to join them
     # note that in order to enable --list as an option we make regions optional but its
     # required for the standard onlist function
     if args.list:
         onlists = run_list_onlists(spec, m)
         for ol in onlists:
             print(f"{ol['region_id']}\t{ol['filename']}\t{ol['location']}\t{ol['md5']}")
         return
-
-    olist = run_onlist(spec, m, r)
+    if args.s == "region":
+        olist = run_onlist_region(spec, m, r, f)
+    elif args.s == "region-type":
+        olist = run_onlist_region_type(spec, m, r, f)
+    elif args.s == "read":
+        olist = run_onlist_read(spec, m, r, f)
     print(os.path.join(os.path.dirname(os.path.abspath(fn)), olist))
     return
 
 
-def run_onlist(spec: Assay, modality: str, region_id: str):
+def run_onlist_region_type(spec: Assay, modality: str, region_type: str, fmt: str):
     # for now return the path to the onlist file for the modality/region pair
 
     # run function
-    regions = run_find_by_type(spec, modality, region_id)
+    regions = run_find_by_type(spec, modality, region_type)
     onlists = []
     for r in regions:
-        onlists.append(r.get_onlist().filename)
+        onlists.append(r.get_onlist())
+    if len(onlists) == 0:
+        raise ValueError(f"No onlist found for region type {region_type}")
+    return join_onlists(onlists, fmt)
+
+
+def run_onlist_region(spec: Assay, modality: str, region_id: str, fmt: str):
+    # for now return the path to the onlist file for the modality/region pair
+
+    # run function
+    regions = run_find(spec, modality, region_id)
+    onlists = []
+    for r in regions:
+        onlists.append(r.get_onlist())
+    if len(onlists) == 0:
+        raise ValueError(f"No onlist found for region {region_id}")
+    return join_onlists(onlists, fmt)
+
 
-    return join_onlists(onlists)
+def run_onlist_read(spec: Assay, modality: str, read_id: str, fmt: str):
+    # for now return the path to the onlist file for the modality/region pair
+
+    # run function
+    (read, rgns) = map_read_id_to_regions(spec, modality, read_id)
+    # convert regions to region coordinates
+    rcs = project_regions_to_coordinates(rgns)
+    # intersect read with region coordinates
+    new_rcs = itx_read(rcs, 0, read.max_len)
+
+    onlists = []
+    for r in new_rcs:
+        ol = r.get_onlist()
+        if ol:
+            onlists.append(ol)
+
+    if len(onlists) == 0:
+        raise ValueError(f"No onlist found for read {read_id}")
+
+    return join_onlists(onlists, fmt)
 
 
 def run_list_onlists(spec: Assay, modality: str):
-    regions = spec.get_modality(modality).get_onlist_regions()
+    regions = spec.get_libspec(modality).get_onlist_regions()
     olsts = []
     for r in regions:
         olsts.append(
             {
                 "region_id": r.region_id,
                 "filename": r.onlist.filename,
                 "location": r.onlist.location,
                 "md5": r.onlist.md5,
             }
         )
     return olsts
 
 
-def join_onlists(onlists):
-    base_path = os.path.dirname(os.path.abspath(onlists[0]))
-    if len(onlists) == 1:
-        return onlists[0]
+def find_list_target_dir(onlists):
+    for olst in onlists:
+        if olst.location == "local":
+            base_path = os.path.dirname(os.path.abspath(onlists[0].filename))
+            if os.access(base_path, os.W_OK):
+                return base_path
+
+    return os.getcwd()
+
+
+def join_onlists(onlists: List[Onlist], fmt: str):
+    """Given a list of onlist objects return a file containing the combined list"""
+    if len(onlists) == 0:
+        print("No lists present")
+        return
+
+    # look to see if the barcode file is present.
+    first_location, first_filename = find_onlist_file(onlists[0])
+    if len(onlists) == 1 and first_location == "local":
+        return first_filename
     else:
+        base_path = find_list_target_dir(onlists)
         # join the onlists
         lsts = [read_list(o) for o in onlists]
         joined_path = os.path.join(base_path, "onlist_joined.txt")
+        formatter_functions = {
+            "product": join_product_onlist,
+            "multi": join_multi_onlist,
+        }
+        formatter = formatter_functions.get(fmt)
+        if formatter is None:
+            raise ValueError(
+                f"Unrecognized format type {fmt}. Expected {', '.join(list(formatter_functions.keys()))}"
+            )
+
         with open(joined_path, "w") as f:
-            for i in itertools.product(*lsts):
-                f.write(f"{''.join(i)}\n")
+            for line in formatter(lsts):
+                f.write(line)
+
         return joined_path
+
+
+def join_product_onlist(lsts):
+    for i in itertools.product(*lsts):
+        yield f"{''.join(i)}\n"
+
+
+def join_multi_onlist(lsts):
+    for row in itertools.zip_longest(*lsts, fillvalue="-"):
+        yield f"{' '.join((str(x) for x in row))}\n"
```

## seqspec/seqspec_print.py

```diff
@@ -1,11 +1,12 @@
 from seqspec.utils import load_spec
 from seqspec.seqspec_print_html import run_print_html
 import newick
-from .utils import REGION_TYPE_COLORS
+from .utils import REGION_TYPE_COLORS, complement_sequence
+from seqspec.Region import project_regions_to_coordinates
 
 
 def setup_print_args(parser):
     subparser = parser.add_parser(
         "print",
         description="print seqspec file",
         help="print seqspec file",
@@ -14,88 +15,198 @@
     subparser.add_argument(
         "-o",
         metavar="OUT",
         help=("Path to output file"),
         type=str,
         default=None,
     )
+
+    format_choices = ["library", "sequence", "libseq"]
+    subparser.add_argument(
+        "-s",
+        metavar="SPEC",
+        help=(
+            f"Specification to print ({', '.join(format_choices)}), default: library"
+        ),
+        type=str,
+        default="library",
+        choices=format_choices,
+    )
+    # TODO: fix naming convention: sequence -> seqspec,
+    # add libspec (list of regions tab delimited)
+    # change tree -> libspec-tree
+    #
+    # actually, add -s which clarifies which spec to print (library or sequence)
+    # then -f should have tree, png, html, sequence
+    format_choices = ["tree", "html", "png", "sequence", "info"]
     subparser.add_argument(
         "-f",
         metavar="FORMAT",
-        help=("Format"),
+        help=(f"Format ({', '.join(format_choices)}), default: tree"),
         type=str,
         default="tree",
-        choices=["tree", "html", "png"],
+        choices=format_choices,
     )
+
     return subparser
 
 
 def validate_print_args(parser, args):
     # if everything is valid the run_print
+    fmt = args.f
+    spectype = args.s
+
+    # validate fmt and spectype pairs, only some are valid
+    if fmt == "png" and spectype != "library":
+        raise ValueError("-f png only valid for -s library")
+    if fmt == "tree" and spectype != "library":
+        raise ValueError("-f tree only valid for -s library")
+    if fmt == "html" and spectype != "library":
+        raise ValueError("-f html only valid for -s library")
+    if fmt == "info" and spectype != "sequence":
+        raise ValueError("-f info only valid for -s sequence")
+    if fmt == "sequence" and spectype != "libseq":
+        raise ValueError("-f sequence only valid for -s libseq")
+
     fn = args.yaml
     o = args.o
-    fmt = args.f
     spec = load_spec(fn)
-    CMD = {
-        "tree": run_print_tree,
+
+    LIBSEQ_CMD = {
+        "sequence": run_print_libseq_sequence,
+    }
+
+    SEQUENCE_CMD = {
+        "info": run_print_sequence_spec,
+    }
+    LIBRARY_CMD = {
+        "tree": run_print_library_tree,
         "html": run_print_html,
-        "png": run_print_png,
+        "png": run_print_library_png,
+    }
+    CMD = {
+        "library": LIBRARY_CMD,
+        "sequence": SEQUENCE_CMD,
+        "libseq": LIBSEQ_CMD,
     }
-    s = CMD[fmt](spec)
+
+    s = CMD[spectype][fmt](spec)
     if fmt == "png":
         s.savefig(o, dpi=300, bbox_inches="tight")
         return
     if o:
         with open(o, "w") as f:
             print(s, file=f)
     else:
         print(s)
 
 
+def run_print_libseq_sequence(spec):
+    p = []
+    for modality in spec.modalities:
+        p.append(libseq(spec, modality))
+    return "\n".join(p)
+
+
+def libseq(spec, modality):
+    libspec = spec.get_libspec(modality)
+    seqspec = spec.get_seqspec(modality)
+
+    p = []
+    n = []
+    leaves = libspec.get_leaves()
+    cuts = project_regions_to_coordinates(leaves)
+    for idx, read in enumerate(seqspec, 1):
+        read_len = read.max_len
+        read_id = read.read_id
+        primer_id = read.primer_id
+        primer_idx = [i for i, l in enumerate(leaves) if l.region_id == primer_id][0]
+        primer_pos = cuts[primer_idx]
+        if read.strand == "pos":
+            wsl = primer_pos.stop - 1
+            ws = wsl * " "
+
+            arrowl = read_len - 1
+            arrow = arrowl * "-"
+
+            p.append(f"{ws}|{arrow}>({idx}) {read_id}")
+        elif read.strand == "neg":
+            wsl = primer_pos.start - read_len
+            ws = wsl * " "
+
+            arrowl = read_len - 1
+            arrow = arrowl * "-"
+
+            n.append(f"{ws}<{arrow}|({idx}) {read_id}")
+
+    s = "\n".join(
+        [
+            modality,
+            "---",
+            "\n".join(p),
+            libspec.sequence,
+            complement_sequence(libspec.sequence),
+            "\n".join(n),
+        ]
+    )
+    return s
+
+
 def run_print(data):
     header = headerTemplate(data.name, data.doi, data.description, data.modalities)
     header2 = "## Final Library"
-    assay_spec = multiModalTemplate(data.assay_spec)
-    s = f"{header}\n{header2}\n{assay_spec}"
+    library_spec = multiModalTemplate(data.library_spec)
+    s = f"{header}\n{header2}\n{library_spec}"
     return s
 
 
-def run_print_tree(spec):
+def run_print_sequence_spec(spec):
+    p = []
+    for r in spec.sequence_spec:
+        p.append(
+            "\t".join(
+                [r.read_id, r.primer_id, r.strand, str(r.min_len), str(r.max_len)]
+            )
+        )
+    return "\n".join(p)
+
+
+def run_print_library_tree(spec):
     t = []
-    for r in spec.assay_spec:
+    for r in spec.library_spec:
         t.append(r.to_newick())
     n = ",".join(t)
     # print(n)
     tree = newick.loads(f"({n})")
     return tree[0].ascii_art()
 
 
 def argsort(arr):
     # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3382369#3382369
     # by unutbu
     return sorted(range(len(arr)), key=arr.__getitem__)
 
 
-def run_print_png(spec):
+def run_print_library_png(spec):
     # builds directly off of https://colab.research.google.com/drive/1ZCIGrwLEIfE0yo33bP8uscUNPEn1p1DH developed by https://github.com/LucasSilvaFerreira
 
     # modality
     modalities = spec.list_modalities()
-    modes = [spec.get_modality(m) for m in modalities]
+    modes = [spec.get_libspec(m) for m in modalities]
     lengths = [i.min_len for i in modes]
     nmodes = len(modalities)
 
     # sort the modalities by their lengths
     asort = argsort(lengths)
     modalities = [modalities[i] for i in asort]
     lengths = [lengths[i] for i in asort]
     modes = [modes[i] for i in asort]
-    assay = spec.assay
+    assay_id = spec.assay_id
 
-    fig, _ = plot_png(assay, modalities, modes, nmodes, lengths)
+    fig, _ = plot_png(assay_id, modalities, modes, nmodes, lengths)
     return fig
 
 
 def plot_png(assay, modalities, modes, nmodes, lengths):
     import matplotlib.pyplot as plt
     from matplotlib.patches import Rectangle
     import matplotlib.patches as mpatches
@@ -147,26 +258,27 @@
 
         ax.autoscale()
 
         # since all axes use the same scale, set the xlim to be 0 to the max length
         ax.set(**{"xlim": (0, max(lengths))})
 
         # hide the spines
-        ax.spines[["right", "top", "left", "bottom"]].set_visible(False)
+        for spine in ["right", "top", "left", "bottom"]:
+            ax.spines[spine].set_visible(False)
         # Hide the axis and ticks and labels
         ax.xaxis.set_visible(False)
         ax.set_yticklabels([])
         ax.set_yticks([])
 
         # label the modality on the ylabel
         ax.set_ylabel(m.region_type, rotation=0, fontsize=20, ha="right", va="center")
 
     # adjust the xaxis for the last modality to show the length
     ax.xaxis.set_visible(True)
-    ax.spines[["bottom"]].set_visible(True)
+    ax.spines["bottom"].set_visible(True)
     ax.minorticks_on()
 
     ax.set(
         **{
             "xlabel": "# nucleotides",
         }
     )
@@ -227,12 +339,12 @@
 
 def libStructTemplate(region):
     s = f"""###### {region.name}
 <pre style="overflow-x: auto; text-align: left; background-color: #f6f8fa">{region.sequence}</pre>"""
     return s
 
 
-def multiModalTemplate(assay_spec):
+def multiModalTemplate(library_spec):
     s = "\n".join(
-        [libStructTemplate(v) + "\n" + regionsTemplate(v.regions) for v in assay_spec]
+        [libStructTemplate(v) + "\n" + regionsTemplate(v.regions) for v in library_spec]
     )
     return s
```

## seqspec/seqspec_print_html.py

```diff
@@ -1,15 +1,15 @@
 from seqspec.Region import Region
 
 
 def run_print_html(spec):
     # header = headerTemplate(spec.name, spec.doi, spec.description, spec.modalities)
     # header2 = "## Final Library"
-    # assay_spec = multiModalTemplate(spec.assay_spec)
-    # s = f"{header}\n{header2}\n{assay_spec}"
+    # library_spec = multiModalTemplate(spec.library_spec)
+    # s = f"{header}\n{header2}\n{library_spec}"
     s = htmlTemplate(spec)
     return s
 
 
 def headerTemplate(name, doi, description, modalities):
     s = f"""<h1 style="text-align: center">{name}</h1>
   <ul>
@@ -123,17 +123,17 @@
     style="overflow-x: auto; text-align: left; background-color: #f6f8fa"
   >
 {colorSeq(region.get_leaves())}</pre>
     """
     return s
 
 
-def multiModalTemplate(assay_spec):
+def multiModalTemplate(library_spec):
     s = "".join(
-        [libStructTemplate(v) + "\n" + regionsTemplate(v.regions) for v in assay_spec]
+        [libStructTemplate(v) + "\n" + regionsTemplate(v.regions) for v in library_spec]
     )
     return s
 
 
 def htmlTemplate(spec):
     s = f"""
   <!DOCTYPE html>
@@ -167,16 +167,16 @@
           {headerTemplate(
             spec.name,
             spec.doi,
             spec.description,
             spec.modalities
           )}
         </div>
-        <div id="assay_spec">
+        <div id="library_spec">
           <h2>Final library</h2>
-          {multiModalTemplate(spec.assay_spec)}
+          {multiModalTemplate(spec.library_spec)}
         </div>
       </div>
     </body>
   </html>
     """
     return s
```

## seqspec/seqspec_split.py

```diff
@@ -36,15 +36,15 @@
             spec.sequencer,
             spec.name,
             spec.doi,
             spec.publication_date,
             spec.description,
             [m],
             spec.lib_struct,
-            [spec.get_modality(m)],
+            [spec.get_libspec(m)],
             spec.seqspec_version,
         )
         spec_m.update_spec()
         base_o = "spec." if os.path.basename(o) == "" else f"{os.path.basename(o)}."
 
         spec_m.to_YAML(os.path.join(os.path.dirname(o), f"{base_o}{m}.yaml"))
```

## seqspec/utils.py

```diff
@@ -1,50 +1,138 @@
 import io
+import os
+import gzip
+from pathlib import Path
 from seqspec.Assay import Assay
+from seqspec.Region import Onlist
+from urllib.parse import urlparse
 import yaml
 import requests
+from Bio import GenBank
 
 
 def load_spec(spec_fn: str):
     with open(spec_fn, "r") as stream:
         return load_spec_stream(stream)
 
 
 def load_spec_stream(spec_stream: io.IOBase):
     data: Assay = yaml.load(spec_stream, Loader=yaml.Loader)
     # set the parent id in the Assay object upon loading it
-    for r in data.assay_spec:
+    for r in data.library_spec:
         r.set_parent_id(None)
     return data
 
 
-# return cut indices for all atomic regions
-def get_cuts(regions, cuts=[]):
-    if not cuts:
-        cuts = []
-    prev = 0
-    for r in regions:
-        nxt = prev + r.max_len
-        cuts.append((prev, nxt))
-        prev = nxt
-    return cuts
+def load_genbank(gbk_fn: str):
+    with open(gbk_fn, "r") as stream:
+        return load_genbank_stream(stream)
+
+
+def load_genbank_stream(gbk_stream: io.IOBase):
+    data: GenBank = GenBank.read(gbk_stream)
+    return data
+
+
+class RegionCoordinate:
+    def __init__(self, cut_name, cut_type, start, end):
+        self.cut_name = cut_name
+        self.cut_type = cut_type
+        self.start = start
+        self.end = end
+
+    def __repr__(self):
+        return f"RegionCoordinate {self.cut_name} [{self.cut_type}]: ({self.start}, {self.end})"
+
+    def __str__(self):
+        return f"RegionCoordinate {self.cut_name} [{self.cut_type}]: ({self.start}, {self.end})"
+
+    def __eq__(self, other):
+        return self.start == other.start and self.end == other.end
 
 
 def write_read(header, seq, qual, f):
     f.write(f"{header}\n{seq}\n+\n{qual}\n")
 
 
-def read_list(fname):
-    with open(fname, "r") as f:
-        return [line.strip() for line in f.readlines()]
+def yield_onlist_contents(stream):
+    for line in stream:
+        yield line.strip().split()[0]
+
+
+def read_list(onlist: Onlist):
+    """Given an onlist object read the local or remote data
+    """
+    location, filename = find_onlist_file(onlist)
+
+    stream = None
+    try:
+        # open stream
+        if location == "remote":
+            auth = get_remote_auth_token()
+            response = requests.get(filename, stream=True, auth=auth)
+            response.raise_for_status()
+            stream = response.raw
+        elif location == "local":
+            stream = open(filename, "rb")
+        else:
+            raise ValueError(
+                "Unsupported location {}. Expected remote or local".format(location))
+
+        # do we need to decompress?
+        if filename.endswith(".gz"):
+            stream = gzip.GzipFile(fileobj=stream)
+
+        # convert to text stream
+        stream = io.TextIOWrapper(stream)
+
+        results = list(yield_onlist_contents(stream))
+    finally:
+        if stream is None:
+            print("Warning: unable to open barcode file {}".format(filename))
+        else:
+            stream.close()
+
+    return results
+
+
+def find_onlist_file(onlist: Onlist):
+    url = urlparse(onlist.filename)
+    pathname = Path(url.path)
+    basename = Path(pathname.name)
+    if basename.exists():
+        # we have a copy of the file in this directory
+        return ("local", str(basename))
+    elif pathname.exists():
+        # we have a path to another directory
+        return ("local", str(pathname))
+    elif url.scheme != '' and onlist.location == "remote":
+        # Should we ignore the location if there's a url scheme?
+        return ("remote", str(onlist.filename))
+    else:
+        raise FileNotFoundError(
+            "No such {} file {}".format(onlist.location, onlist.filename))
+
+
+def get_remote_auth_token():
+    """Look for authentication tokens for accessing remote resources
+    """
+    username = os.environ.get("IGVF_API_KEY")
+    password = os.environ.get("IGVF_SECRET_KEY")
+    if not (username is None or password is None):
+        auth = (username, password)
+    else:
+        auth = None
+
+    return auth
 
 
 def region_ids_in_spec(seqspec, modality, region_ids):
     # return True if all region_ids are in seqspec
-    spec = seqspec.get_modality(modality)
+    spec = seqspec.get_libspec(modality)
     found = []
     for region_id in region_ids:
         found += [r.region_id for r in spec.get_region_by_id(region_id)]
     return found
 
 
 def file_exists(uri):
@@ -54,14 +142,15 @@
     except requests.ConnectionError:
         return False
 
 
 REGION_TYPE_COLORS = {
     "barcode": "#2980B9",
     "cdna": "#8E44AD",
+    "custom_primer": "#3CB371",
     "fastq": "#F1C40F",
     "gdna": "#E67E22",
     "illumina_p5": "#E17A47",
     "illumina_p7": "#E17A47",
     "index5": "#4AB19D",
     "index7": "#4AB19D",
     "linker": "#1ABC9C",
@@ -82,7 +171,52 @@
     "protein": "#ECF0F1",
 }
 
 
 # unused
 # '#FF8C00'
 # '#95A5A6'
+
+
+def complement_nucleotide(nucleotide):
+    complements = {
+        "A": "T",
+        "T": "A",
+        "G": "C",
+        "C": "G",
+        "R": "Y",
+        "Y": "R",
+        "S": "S",
+        "W": "W",
+        "K": "M",
+        "M": "K",
+        "B": "V",
+        "D": "H",
+        "V": "B",
+        "H": "D",
+        "N": "N",
+        "X": "X",
+    }
+    return complements.get(
+        nucleotide, "N"
+    )  # Default to 'N' if nucleotide is not recognized
+
+
+def complement_sequence(sequence):
+    return "".join(complement_nucleotide(n) for n in sequence.upper())
+
+
+def map_read_id_to_regions(spec, modality, region_id):
+    # get all atomic elements from library
+    leaves = spec.get_libspec(modality).get_leaves()
+    # get the read object and primer id
+    read = [i for i in spec.sequence_spec if i.read_id == region_id][0]
+    primer_id = read.primer_id
+    # get the index of the primer in the list of leaves (ASSUMPTION, 5'->3' and primer is an atomic element)
+    primer_idx = [i for i, l in enumerate(leaves) if l.region_id == primer_id][0]
+    # If we are on the opposite strand, we go in the opposite way
+    if read.strand == "neg":
+        rgns = leaves[:primer_idx][::-1]
+    else:
+        rgns = leaves[primer_idx + 1 :]
+
+    return (read, rgns)
```

## seqspec/schema/seqspec.schema.json

### Pretty-printed

 * *Similarity: 0.8895833333333334%*

 * *Differences: {"'$defs'": "{'read': OrderedDict([('title', 'Read'), ('type', 'object'), ('properties', "*

 * *            "OrderedDict([('read_id', OrderedDict([('type', 'string'), ('description', 'The unique "*

 * *            "identifier for the read.')])), ('name', OrderedDict([('type', 'string'), "*

 * *            "('description', 'The name of the read.')])), ('modality', OrderedDict([('type', "*

 * *            "'string'), ('description', 'The modality of the assay generating the read.')])), "*

 * *            "('primer_id', OrderedDict([( []*

```diff
@@ -1,9 +1,58 @@
 {
     "$defs": {
+        "read": {
+            "additionalProperties": false,
+            "properties": {
+                "max_len": {
+                    "description": "The maximum length of the read, must be greater than 0.",
+                    "exclusiveMinimum": 0,
+                    "type": "integer"
+                },
+                "min_len": {
+                    "description": "The minimum length of the read, must be greater than or equal to 0.",
+                    "minimum": 0,
+                    "type": "integer"
+                },
+                "modality": {
+                    "description": "The modality of the assay generating the read.",
+                    "type": "string"
+                },
+                "name": {
+                    "description": "The name of the read.",
+                    "type": "string"
+                },
+                "primer_id": {
+                    "description": "The region id of the primer used.",
+                    "type": "string"
+                },
+                "read_id": {
+                    "description": "The unique identifier for the read.",
+                    "type": "string"
+                },
+                "strand": {
+                    "description": "The strand orientation of the read, either positive ('pos') or negative ('neg').",
+                    "enum": [
+                        "pos",
+                        "neg"
+                    ],
+                    "type": "string"
+                }
+            },
+            "required": [
+                "read_id",
+                "modality",
+                "primer_id",
+                "min_len",
+                "max_len",
+                "strand"
+            ],
+            "title": "Read",
+            "type": "object"
+        },
         "region": {
             "description": "A region of DNA",
             "properties": {
                 "max_len": {
                     "description": "The maximum length of the sequence",
                     "maximum": 2048,
                     "minimum": 0,
@@ -119,37 +168,50 @@
             "type": "object"
         }
     },
     "$id": "Assay.schema.json",
     "$schema": "https://json-schema.org/draft/2020-12/schema",
     "description": "A Assay of DNA",
     "properties": {
-        "assay": {
-            "description": "The name of the assay",
+        "assay_id": {
+            "description": "Identifier for the assay",
             "type": "string"
         },
-        "assay_spec": {
-            "description": "The spec for the assay",
-            "items": {
-                "$ref": "#/$defs/region"
-            },
-            "type": "array"
+        "date": {
+            "description": "The seqspec creation date",
+            "pattern": "^(0?[1-9]|[12][0-9]|3[01])\\s(January|February|March|April|May|June|July|August|September|October|November|December)\\s(19|20)\\d\\d$",
+            "type": "string"
         },
         "description": {
             "description": "A short description of the assay",
             "type": "string"
         },
         "doi": {
             "description": "the doi of the paper that describes the assay",
             "type": "string"
         },
         "lib_struct": {
             "description": "The link to Teichmann's libstructs page derived for this sequence",
             "type": "string"
         },
+        "library_kit": {
+            "description": "The kit used to make the library sequence_protocol compatible",
+            "type": "string"
+        },
+        "library_protocol": {
+            "description": "The protocol/machine/tool to generate the library insert",
+            "type": "string"
+        },
+        "library_spec": {
+            "description": "The spec for the assay",
+            "items": {
+                "$ref": "#/$defs/region"
+            },
+            "type": "array"
+        },
         "modalities": {
             "description": "The modalities the assay targets",
             "items": {
                 "enum": [
                     "dna",
                     "rna",
                     "tag",
@@ -161,35 +223,45 @@
             },
             "type": "array"
         },
         "name": {
             "description": "The name of the assay",
             "type": "string"
         },
-        "publication_date": {
-            "description": "the publication date of the paper/announcement that describes the assay",
-            "type": "string"
-        },
         "seqspec_version": {
             "description": "Version of the seqspec specification used",
             "pattern": "^(0|[1-9]\\d*)\\.(0|[1-9]\\d*)\\.(0|[1-9]\\d*)(?:-((?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\.(?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\\+([0-9a-zA-Z-]+(?:\\.[0-9a-zA-Z-]+)*))?$",
             "type": "string"
         },
-        "sequencer": {
-            "description": "The sequencer used to sequence the library",
+        "sequence_kit": {
+            "description": "The kit used with the protocol to sequence the library",
             "type": "string"
+        },
+        "sequence_protocol": {
+            "description": "The protocol/machine/tool to generate sequences",
+            "type": "string"
+        },
+        "sequence_spec": {
+            "description": "The spec for the sequencer",
+            "items": {
+                "$ref": "#/$defs/read"
+            },
+            "type": "array"
         }
     },
     "required": [
         "seqspec_version",
-        "sequencer",
-        "assay",
+        "assay_id",
         "name",
         "doi",
-        "publication_date",
+        "date",
         "description",
         "modalities",
-        "lib_struct"
+        "lib_struct",
+        "library_protocol",
+        "library_kit",
+        "sequence_protocol",
+        "sequence_kit"
     ],
     "title": "Assay",
     "type": "object"
 }
```

## Comparing `seqspec-0.1.1.dist-info/LICENSE` & `seqspec-0.2.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `seqspec-0.1.1.dist-info/METADATA` & `seqspec-0.2.0.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: seqspec
-Version: 0.1.1
+Version: 0.2.0
 Home-page: https://github.com/sbooeshaghi/seqspec
 Author: Sina Booeshaghi
 Author-email: abooesha@caltech.edu
 Maintainer: Sina Booeshaghi
 Maintainer-email: abooesha@caltech.edu
 License: MIT
 Classifier: Environment :: Console
@@ -21,27 +21,28 @@
 Requires-Python: >=3.6
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: pyyaml >=6.0
 Requires-Dist: jsonschema
 Requires-Dist: newick
 Requires-Dist: requests
+Requires-Dist: biopython
 
 # seqspec
 
-![github version](https://img.shields.io/badge/Version-0.1.1-informational)
-[![pypi version](https://img.shields.io/pypi/v/seqspec)](https://pypi.org/project/seqspec/0.1.1/)
+![github version](https://img.shields.io/badge/Version-0.2.0-informational)
+[![pypi version](https://img.shields.io/pypi/v/seqspec)](https://pypi.org/project/seqspec/0.2.0/)
 ![python versions](https://img.shields.io/pypi/pyversions/seqspec)
 [![license](https://img.shields.io/pypi/l/seqspec)](LICENSE)
 
 `seqspec` is a machine-readable YAML file format for genomic library sequence and structure. It was inspired by and builds off of the Teichmann Lab [Single Cell Genomics Library Structure](https://github.com/Teichlab/scg_lib_structs) by [Xi Chen](https://github.com/dbrg77).
 
 Genomic library structure depends on both the assay and sequencer (and kit) used to generate and bind the assay-specific construct to the sequencing adapters to generate a sequencing library. Therefore, a `seqspec` is specific to both a genomics assay and sequencer.
 
-A list of `seqspec` examples for multiple assays and sequencers can be found on [this website](https://igvf.github.io/seqspec/). Each `spec.yaml` describes the 5'->3' "Final library structure" for the assay and sequencer. Sequence specification files can be formatted with the `seqspec` command line tool.
+A list of `seqspec` examples for multiple assays and sequencers can be found on [this website](https://igvf.github.io/seqspec/). Each `spec.yaml` describes the 5'->3' "Final library structure" for the assay and sequencer and can be extended to include sequencer-specific read annotations. Sequence specification files can be formatted with the `seqspec` command line tool.
 
 <img alt="image" src="/docs/seqspec.png">
 
 ```bash
 # release
 pip install seqspec
```

## Comparing `seqspec-0.1.1.dist-info/RECORD` & `seqspec-0.2.0.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,25 +1,26 @@
-seqspec/Assay.py,sha256=lrWpdsqQFoLf-otTfIAJ-a3mY9ud_qDbMs8Xlr8Pjq8,2552
-seqspec/Region.py,sha256=qkhzTz1YLd8LIJN3495mHOpSE-QR-2Pp-pmwTm5YNZM,7053
-seqspec/__init__.py,sha256=rnObPjuBcEStqSO0S6gsdS_ot8ITOQjVj_-P1LUUYpg,22
-seqspec/main.py,sha256=-tivQ832_5JP3eIXn534ESlCNvZ0GhAywhU3PCdTuF0,3174
-seqspec/seqspec_check.py,sha256=rdbjM6yxrFEcfHqMaCxOkCBolAA34WWzkuyJCsoEOjM,5222
+seqspec/Assay.py,sha256=OJ8v715ckKSYrz33zOEbfRmdnWiKRKXM09jXwH9Dpao,3495
+seqspec/Region.py,sha256=2jTIkx7DFfM2Bdno-sm-2C3noZgCdFNQFfKpqqeHMlw,11169
+seqspec/__init__.py,sha256=Zn1KFblwuFHiDRdRAiRnDBRkbPttWh44jKa5zG2ov0E,22
+seqspec/main.py,sha256=9Lsf5FuTHiuBkR1zG5iHTmb7GamWnqx-QJSQtQ0bg9A,3265
+seqspec/seqspec_check.py,sha256=atwBxSA1l397cLlca9EesT0T1K87iNocU49ayCRqUpQ,10809
 seqspec/seqspec_diff.py,sha256=q35tr9CzpACDzqfyrNfrkiFafHMyKEVUWIK38Qc6Vh0,1075
-seqspec/seqspec_find.py,sha256=ELidmRLDiCfjV_bgcNYRxAf4pUC8VK5KDmfXf_8IYkY,1893
+seqspec/seqspec_find.py,sha256=ZHmiKR4mXU_JLn0W4bZ27anoVEGPvR_kU7s4nXqxeXY,1898
 seqspec/seqspec_format.py,sha256=VyEbpq38mDMRhmLc3LgNiCXoUPRGbcGret1ouT20-qo,797
-seqspec/seqspec_index.py,sha256=0mjWxkLl0Uh25cukRzAiX_j7pQ49SqcSf8wcvkfES2k,7967
-seqspec/seqspec_info.py,sha256=9p8gILiiPd28h7nTC7q3ikG7iziEnPP_cUibl0I6g3U,970
-seqspec/seqspec_init.py,sha256=zAvzCvq_vFinZn5ZVAeKyAP12uMLHHS1EYLjYckyhIk,3323
-seqspec/seqspec_modify.py,sha256=mZy36EDc9EtGmj9-JGHAmkpz1lCosrHFJsV4MK-l_3I,3433
-seqspec/seqspec_onlist.py,sha256=mGfAIRVfE2T7uQINQbsSDmuMf9xrMXl_DZLhGhoRXz4,3025
-seqspec/seqspec_print.py,sha256=yYJSNLXChAHpouIbSX0jtcLnqLm2sV5LI6PR05s-3rU,6601
-seqspec/seqspec_print_html.py,sha256=YrwQ-9_7Dw5bcH5IS8VB3zTOZDwG7ULYXyWkc7U63-0,4215
-seqspec/seqspec_split.py,sha256=HtvRKByJ53iCkhju5OWPMRWm9uxoBfpl2Z31SBeNC1E,1409
+seqspec/seqspec_genbank.py,sha256=WL_nX1QsFEE4mEf5RxjtU0p7BdbG0uBwZ4gs2MSvmSg,5509
+seqspec/seqspec_index.py,sha256=jOlNjkRcJP6EMRdeVqSuzCZKocGVq46T2OV0UlQFCGg,9405
+seqspec/seqspec_info.py,sha256=6QJxCK5e4RA2yLvMbxKwllnzf9mXtNLGgbsU8FP59eU,972
+seqspec/seqspec_init.py,sha256=np8_mMERHnYQC5Lzmynzdq1DzWDV3nvp0Sn3CZY-CkA,3327
+seqspec/seqspec_modify.py,sha256=OIo6GN1omibXJ9HOgq-ypLbelGp7uJxVFWQRUoaY1oc,3432
+seqspec/seqspec_onlist.py,sha256=RFCRmr4NXPWc6btUvgEpgMNlitXkEbyChlHi3BoULdI,6450
+seqspec/seqspec_print.py,sha256=2OtHg8MJV8WXaVPGMR4ZeBaoUC176pJJsLVhDA60yfo,9954
+seqspec/seqspec_print_html.py,sha256=b2luBHzG3Td9Gvtcy3fZmPe9RjPYCe8Rjuor1bF9t4M,4229
+seqspec/seqspec_split.py,sha256=gJEQtehAAjZvaMMpLE0Z7RCj-N315KrNxcwxhWPu50I,1408
 seqspec/seqspec_version.py,sha256=zWc4uZw62OlD78l-NqzPTDSPgcrANd3p_x7mdLd73Uo,955
-seqspec/utils.py,sha256=vTfX_XL9YF8lwJFo8CJvxFgYTLmo0hwKRvDQTSaKmrA,1990
-seqspec/schema/seqspec.schema.json,sha256=PDtvk0Aem63jcQBxl3BQYy0bfl8ZEcb_WtWaYUHFhOU,4718
-seqspec-0.1.1.dist-info/LICENSE,sha256=2RxceSFuJADzk1ku3xRByEkZkfZEXUMFPJ1bGX0h9yU,1072
-seqspec-0.1.1.dist-info/METADATA,sha256=x3eIoOiswfSZlzTHhSuZqTjT8_LOvQ9cQH3n7GISfmo,2778
-seqspec-0.1.1.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-seqspec-0.1.1.dist-info/entry_points.txt,sha256=N_5ys2tRy1-FIJ3-fJeLoPfPG7fipIDC90ke5gDWIEQ,46
-seqspec-0.1.1.dist-info/top_level.txt,sha256=0GXZyf0K5XROhwuF_Wsvd2Pp0-ZrX-fb-izG6EcElvo,8
-seqspec-0.1.1.dist-info/RECORD,,
+seqspec/utils.py,sha256=Lq-ntSbOrFU7K4f6c4evEImNd-h0-peyKI1PJ82VWvk,5999
+seqspec/schema/seqspec.schema.json,sha256=QPHGE4VYniHVgmyQ7os8R1yIaxdXKpUrCjMqxx7AOu0,6785
+seqspec-0.2.0.dist-info/LICENSE,sha256=2RxceSFuJADzk1ku3xRByEkZkfZEXUMFPJ1bGX0h9yU,1072
+seqspec-0.2.0.dist-info/METADATA,sha256=hS94LWygDUfMbAaYTEKJcuu7S4eHuDVHufrWGRGjwPI,2870
+seqspec-0.2.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+seqspec-0.2.0.dist-info/entry_points.txt,sha256=N_5ys2tRy1-FIJ3-fJeLoPfPG7fipIDC90ke5gDWIEQ,46
+seqspec-0.2.0.dist-info/top_level.txt,sha256=0GXZyf0K5XROhwuF_Wsvd2Pp0-ZrX-fb-izG6EcElvo,8
+seqspec-0.2.0.dist-info/RECORD,,
```

